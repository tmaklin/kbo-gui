diff --git a/Cargo.toml b/Cargo.toml
index 91e7ba9..521118a 100644
--- a/Cargo.toml
+++ b/Cargo.toml
@@ -1,72 +1,30 @@
-# THIS FILE IS AUTOMATICALLY GENERATED BY CARGO
-#
-# When uploading crates to the registry Cargo will automatically
-# "normalize" Cargo.toml files for maximal compatibility
-# with all versions of Cargo and also rewrite `path` dependencies
-# to registry (e.g., crates.io) dependencies.
-#
-# If you are reading this file be aware that the original Cargo.toml
-# will likely look very different (and much more reasonable).
-# See Cargo.toml.orig for the original contents.
-
 [package]
-edition = "2021"
-rust-version = "1.77"
 name = "sbwt"
 version = "0.3.2"
-authors = ["Jarno Niklas Alanko <alanko.jarno@gmail.com>"]
-description = "Indexing sets of DNA k-mers with the spectral Burrow-Wheeler transform."
-readme = "README.md"
+edition = "2021"
+rust-version = "1.77" # 1.77 needed for File::create_new
 license = "MIT"
+description = "Indexing sets of DNA k-mers with the spectral Burrow-Wheeler transform."
 repository = "https://github.com/jnalanko/sbwt-rs-cli/tree/master/api"
+authors = ["Jarno Niklas Alanko <alanko.jarno@gmail.com>"]
 
-[dependencies.bitvec]
-version = "1.0.1"
-
-[dependencies.byteorder]
-version = "1.5"
-
-[dependencies.chrono]
-version = "0.4"
-
-[dependencies.clap]
-version = "4.4"
-
-[dependencies.crossbeam]
-version = "0.5"
-
-[dependencies.embed-doc-image]
-version = "0.1.4"
-
-[dependencies.env_logger]
-version = "0.10"
-
-[dependencies.jseqio]
-version = "0.1.3"
-
-[dependencies.log]
-version = "0.4"
-
-[dependencies.num]
-version = "0.4"
-
-[dependencies.rand]
-version = "0.7"
-
-[dependencies.rayon]
-version = "1"
-
-[dependencies.read_exact]
-version = "0.0.1"
-
-[dependencies.simple-sds-sbwt]
-version = "0.3.1"
-
-[dependencies.test-log]
-version = "0.2"
-
-[dependencies.unitig_flipper]
-version = "0.1.0"
-
-[dev-dependencies.rand_chacha]
-version = "0.3.1"
+[dependencies]
+rayon = "1"
+num = "0.4"
+simple-sds-sbwt = "0.3.1"
+clap = "4.4"
+jseqio = "0.1.3"
+unitig_flipper = "0.1.0" 
+env_logger = "0.10"
+log = "0.4"
+crossbeam = "0.5"
+read_exact = "0.0.1"
+bitvec = "1.0.1"
+rand = "0.7"
+test-log = "0.2"
+byteorder = "1.5"
+chrono = "0.4"
+embed-doc-image = "0.1.4"
+
+[dev-dependencies]
+rand_chacha = "0.3.1" # Seeded rng in tests
diff --git a/src/bitpacked_kmer_sorting/cursors.rs b/src/bitpacked_kmer_sorting/cursors.rs
index d01ce41..b62f12f 100644
--- a/src/bitpacked_kmer_sorting/cursors.rs
+++ b/src/bitpacked_kmer_sorting/cursors.rs
@@ -1,10 +1,11 @@
-use std::{io::{BufReader, Seek, Read}, fs::File, path::Path};
+use std::io::{BufReader, Seek, Read};
 
 use simple_sds_sbwt::{ops::Access, raw_vector::AccessRaw};
 use std::io::SeekFrom;
 use std::cmp::min;
 use super::kmer::LongKmer;
-use crate::util::binary_search_leftmost_that_fulfills_pred;
+use crate::util::binary_search_leftmost_that_fulfills_pred_mut;
+use crate::tempfile::TempFile;
 
 pub struct DummyNodeMerger<R: std::io::Read, const B: usize> {
     dummy_reader: R, // Stream of k-mer objects
@@ -110,7 +111,7 @@ impl <R: std::io::Read, const B: usize> DummyNodeMerger<R, B> {
     }
 }
 
-impl<const B: usize> Iterator for DummyNodeMerger<BufReader<File>, B> {
+impl<const B: usize> Iterator for DummyNodeMerger<&mut TempFile, B> {
     type Item = (LongKmer<B>, u8);
 
     // Produces pairs (kmer, length)
@@ -143,28 +144,93 @@ impl<const B: usize> Iterator for DummyNodeMerger<BufReader<File>, B> {
 
 }
 
+
+impl<const B: usize> Iterator for DummyNodeMerger<std::io::Cursor<Vec<u8>>, B> {
+    type Item = (LongKmer<B>, u8);
+
+    // Produces pairs (kmer, length)
+    fn next(&mut self) -> Option<(LongKmer::<B>, u8)> {
+        match (self.dummy_kmer, self.nondummy_kmer){
+            (None, None) => None,
+            (Some(dummy_kmer), None) => {
+                self.dummy_kmer = Self::read_from_dummy_reader(&mut self.dummy_reader);
+                self.dummy_position += 1;
+                Some(dummy_kmer)
+            },
+            (None, Some(nondummy_kmer)) => {
+                self.nondummy_kmer = Self::read_from_non_dummy_reader(&mut self.nondummy_reader, self.k);
+                self.nondummy_position += 1;
+                Some(nondummy_kmer)
+            },
+            (Some(dummy_kmer), Some(nondummy_kmer)) => {
+                if dummy_kmer < nondummy_kmer {
+                    self.dummy_kmer = Self::read_from_dummy_reader(&mut self.dummy_reader);
+                    self.dummy_position += 1;
+                    Some(dummy_kmer)
+                } else {
+                    self.nondummy_kmer = Self::read_from_non_dummy_reader(&mut self.nondummy_reader, self.k);
+                    self.nondummy_position += 1;
+                    Some(nondummy_kmer)
+                }
+            }
+        }
+    }
+
+}
+
+impl<const B: usize> Iterator for DummyNodeMerger<&mut std::io::Cursor<Vec<u8>>, B> {
+    type Item = (LongKmer<B>, u8);
+
+    // Produces pairs (kmer, length)
+    fn next(&mut self) -> Option<(LongKmer::<B>, u8)> {
+        match (self.dummy_kmer, self.nondummy_kmer){
+            (None, None) => None,
+            (Some(dummy_kmer), None) => {
+                self.dummy_kmer = Self::read_from_dummy_reader(&mut self.dummy_reader);
+                self.dummy_position += 1;
+                Some(dummy_kmer)
+            },
+            (None, Some(nondummy_kmer)) => {
+                self.nondummy_kmer = Self::read_from_non_dummy_reader(&mut self.nondummy_reader, self.k);
+                self.nondummy_position += 1;
+                Some(nondummy_kmer)
+            },
+            (Some(dummy_kmer), Some(nondummy_kmer)) => {
+                if dummy_kmer < nondummy_kmer {
+                    self.dummy_kmer = Self::read_from_dummy_reader(&mut self.dummy_reader);
+                    self.dummy_position += 1;
+                    Some(dummy_kmer)
+                } else {
+                    self.nondummy_kmer = Self::read_from_non_dummy_reader(&mut self.nondummy_reader, self.k);
+                    self.nondummy_position += 1;
+                    Some(nondummy_kmer)
+                }
+            }
+        }
+    }
+}
+
 // We take in Paths instead of a Files because we need multiple readers to the same files 
-pub fn init_char_cursors<const B: usize>(dummy_filepath: &Path, nondummy_filepath: &Path, k: usize, sigma: usize)
--> Vec<DummyNodeMerger<BufReader<File>, B>>{
-    let mut char_cursors = Vec::<DummyNodeMerger<BufReader<File>, B>>::new();
+pub fn init_char_cursors<const B: usize>(dummy_file: &mut TempFile, nondummy_file: &mut TempFile, k: usize, sigma: usize)
+-> Vec<DummyNodeMerger<std::io::Cursor<Vec<u8>>, B>>{
+    let mut char_cursors = Vec::<DummyNodeMerger<std::io::Cursor<Vec<u8>>, B>>::new();
     for c in 0..(sigma as u8){
         log::trace!("Searching character {}", c);
 
         let (dummy_reader, dummy_pos) = 
         { // Seek in dummies
 
-            let dummy_file_len = std::fs::metadata(dummy_filepath).unwrap().len() as usize;
+            let dummy_file_len = dummy_file.avail_in() as usize;
             let dummy_record_len = LongKmer::<B>::byte_size() + 1; // Pairs (kmer, len byte)
             assert_eq!(dummy_file_len % dummy_record_len, 0);
     
             let access_fn = |pos| {
-                let mut f = File::open(dummy_filepath).unwrap();
-                f.seek(SeekFrom::Start(pos as u64 * dummy_record_len as u64)).unwrap();
-                let kmer = LongKmer::<B>::load(&mut f).unwrap().unwrap(); // Should never be none because we know the file length
+                dummy_file.file.seek(SeekFrom::Start(pos as u64 * dummy_record_len as u64)).unwrap();
+                let kmer = LongKmer::<B>::load(&mut dummy_file.file).unwrap().unwrap(); // Should never be none because we know the file length
 
                 // Read the length byte
                 let mut len_buf = [0_u8; 1];
-                f.read_exact(&mut len_buf).unwrap();
+                dummy_file.file.read_exact(&mut len_buf).unwrap();
                 let len = u8::from_le_bytes(len_buf);
                 (kmer, len)
             };
@@ -173,55 +239,53 @@ pub fn init_char_cursors<const B: usize>(dummy_filepath: &Path, nondummy_filepat
                 kmer.1 > 0 && kmer.0.get_from_left(0) >= c
             };
 
-            let start = binary_search_leftmost_that_fulfills_pred(
+            let start = binary_search_leftmost_that_fulfills_pred_mut(
                 access_fn, 
                 pred_fn, 
                 dummy_file_len / dummy_record_len);
 
-            let mut f = File::open(dummy_filepath).unwrap();
-            f.seek(SeekFrom::Start(start as u64 * dummy_record_len as u64)).unwrap();
-            (BufReader::new(f), start)
+            dummy_file.file.seek(SeekFrom::Start(start as u64 * dummy_record_len as u64)).unwrap();
+            (dummy_file.file.clone(), start)
         };
 
         let (nondummy_reader, nondummy_pos) = 
         { // Seek in nondummies
 
-            let nondummy_file_len = std::fs::metadata(nondummy_filepath).unwrap().len() as usize;
+            let nondummy_file_len = nondummy_file.avail_in() as usize;
             let nondummy_record_len = LongKmer::<B>::byte_size();
             assert_eq!(nondummy_file_len % nondummy_record_len, 0);
     
             let access_fn = |pos| {
-                let mut f = File::open(nondummy_filepath).unwrap();
-                f.seek(SeekFrom::Start(pos as u64 * nondummy_record_len as u64)).unwrap();
-                LongKmer::<B>::load(&mut f).unwrap().unwrap() // Should never be None because we know the file length
+		nondummy_file.file.seek(SeekFrom::Start(pos as u64 * nondummy_record_len as u64)).unwrap();
+                LongKmer::<B>::load(&mut nondummy_file.file).unwrap().unwrap() // Should never be None because we know the file length
             };
 
             let pred_fn = |kmer: LongKmer::<B>| {
                 kmer.get_from_left(0) >= c
             };
 
-            let start = binary_search_leftmost_that_fulfills_pred(
+            let start = binary_search_leftmost_that_fulfills_pred_mut(
                 access_fn, 
                 pred_fn, 
                 nondummy_file_len / nondummy_record_len);
-        
-            let mut f = File::open(nondummy_filepath).unwrap();
-            f.seek(SeekFrom::Start(start as u64 * nondummy_record_len as u64)).unwrap();
-            (BufReader::new(f), start)
+
+            nondummy_file.file.seek(SeekFrom::Start(start as u64 * nondummy_record_len as u64)).unwrap();
+	    (nondummy_file.file.clone(), start)
         };
 
         let cursor = DummyNodeMerger::new_with_initial_positions(dummy_reader, nondummy_reader, k, dummy_pos, nondummy_pos);
         char_cursors.push(cursor);
     }
 
+    nondummy_file.file.seek(SeekFrom::Start(0)).unwrap();
     char_cursors
 
 }
 
 // Returns the SBWT bit vectors and optionally the LCS array
 pub fn build_sbwt_bit_vectors<const B: usize>(
-    global_cursor: DummyNodeMerger<BufReader<File>, B>, 
-    mut char_cursors: Vec<DummyNodeMerger<BufReader<File>, B>>, 
+    global_cursor: DummyNodeMerger<&mut TempFile, B>,
+    mut char_cursors: Vec<DummyNodeMerger<std::io::Cursor<Vec<u8>>, B>>,
     n: usize,
     k: usize, 
     sigma: usize,
@@ -307,12 +371,10 @@ mod tests{
             (LongKmer::<2>::from_ascii(b"GGTT").unwrap(),3),
         ];
 
-        let mut temp_file_manager = crate::tempfile::TempFileManager::new(std::path::Path::new("temp"));
+        let mut temp_file_manager = crate::tempfile::TempFileManager::new();
 
         let mut nondummy_file = temp_file_manager.create_new_file("test-", 10, ".nondummy");
         let mut dummy_file = temp_file_manager.create_new_file("test-", 10, ".dummy");
-        let nondummy_path = nondummy_file.path.clone();
-        let dummy_path = dummy_file.path.clone();
 
         for kmer in nondummies.iter(){
             kmer.serialize(&mut nondummy_file).unwrap();
@@ -327,7 +389,7 @@ mod tests{
         dummy_file.flush().unwrap();
         nondummy_file.flush().unwrap();
 
-        let char_cursors = init_char_cursors(&dummy_path, &nondummy_path, 4, 4);
+        let char_cursors = init_char_cursors(&mut dummy_file, &mut nondummy_file, 4, 4);
 
         assert_eq!(char_cursors[0].peek(), Some((LongKmer::<2>::from_ascii(b"AAAA").unwrap(), 1))); // A
         assert_eq!(char_cursors[1].peek(), Some((LongKmer::<2>::from_ascii(b"GGAA").unwrap(), 4))); // C
@@ -335,4 +397,4 @@ mod tests{
         assert_eq!(char_cursors[3].peek(), None); // T
 
     }
-}
\ No newline at end of file
+}
diff --git a/src/bitpacked_kmer_sorting/dummies.rs b/src/bitpacked_kmer_sorting/dummies.rs
index 8a1c909..276513a 100644
--- a/src/bitpacked_kmer_sorting/dummies.rs
+++ b/src/bitpacked_kmer_sorting/dummies.rs
@@ -1,7 +1,10 @@
 use std::io::{BufWriter, Write};
+use std::io::Seek;
+use std::io::SeekFrom;
 
 use super::kmer::LongKmer;
 use crate::tempfile::TempFileManager;
+use crate::tempfile::TempFile;
 use simple_sds_sbwt::raw_vector::*;
 use rayon::prelude::*;
 
@@ -14,23 +17,23 @@ impl std::io::Read for NullReader{
 }
 
 // We take in a path and not a file object because we need multiple readers to the same file
-pub fn get_sorted_dummies<const B: usize>(sorted_kmers_filepath: &std::path::Path, sigma: usize, k: usize, temp_file_manager: &mut TempFileManager) -> Vec<(LongKmer::<B>, u8)>{
+pub fn get_sorted_dummies<const B: usize>(sorted_kmers: &mut TempFile, sigma: usize, k: usize, temp_file_manager: &mut TempFileManager) -> Vec<(LongKmer::<B>, u8)>{
 
     // Todo: I'm using dummy merger cursors with an empty dummy file. Should refactor things to manage without the
     // empty dummy file.
 
     // Number of k-mers in file
-    let n = std::fs::metadata(sorted_kmers_filepath).unwrap().len() as usize / LongKmer::<B>::byte_size();
+    let n = sorted_kmers.avail_in() as usize / LongKmer::<B>::byte_size();
 
     let mut has_predecessor = simple_sds_sbwt::raw_vector::RawVector::new();
     has_predecessor.resize(n, false);
 
-    let emptyfile = temp_file_manager.create_new_file("empty-", 10, ".bin");
-    let mut char_cursors = crate::bitpacked_kmer_sorting::cursors::init_char_cursors::<B>(&emptyfile.path, sorted_kmers_filepath, k, sigma);
+    let mut emptyfile = temp_file_manager.create_new_file("empty-", 10, ".bin");
+    let mut char_cursors = crate::bitpacked_kmer_sorting::cursors::init_char_cursors::<B>(&mut emptyfile, sorted_kmers, k, sigma);
 
     let global_cursor = crate::bitpacked_kmer_sorting::cursors::DummyNodeMerger::new(
-        std::io::BufReader::new(std::fs::File::open(&emptyfile.path).unwrap()),
-        std::io::BufReader::new(std::fs::File::open(sorted_kmers_filepath).unwrap()),
+        &mut emptyfile,
+        sorted_kmers,
         k,
     );
 
@@ -56,9 +59,13 @@ pub fn get_sorted_dummies<const B: usize>(sorted_kmers_filepath: &std::path::Pat
         }
     }
 
+    // Rewind cursors
+    emptyfile.file.seek(SeekFrom::Start(0)).unwrap();
+    sorted_kmers.file.seek(SeekFrom::Start(0)).unwrap();
+
     let mut global_cursor = crate::bitpacked_kmer_sorting::cursors::DummyNodeMerger::new(
-        std::io::BufReader::new(std::fs::File::open(&emptyfile.path).unwrap()),
-        std::io::BufReader::new(std::fs::File::open(sorted_kmers_filepath).unwrap()),
+        &mut emptyfile,
+        sorted_kmers,
         k,
     ); // New global cursor
 
@@ -89,11 +96,11 @@ pub fn get_sorted_dummies<const B: usize>(sorted_kmers_filepath: &std::path::Pat
 
 }
 
-pub fn write_to_disk<const B: usize>(dummies: Vec<(LongKmer::<B>, u8)>, writer: &mut std::fs::File){   
+pub fn write_to_disk<const B: usize>(dummies: Vec<(LongKmer::<B>, u8)>, writer: &mut TempFile){
     let mut bw = BufWriter::new(writer);
     for (kmer, len) in dummies.iter(){
         kmer.serialize(&mut bw).unwrap();
         bw.write_all(&[*len]).unwrap();
     }
     bw.flush().unwrap();
-}
\ No newline at end of file
+}
diff --git a/src/bitpacked_kmer_sorting/kmer_splitter.rs b/src/bitpacked_kmer_sorting/kmer_splitter.rs
index 79eb686..d8fd496 100644
--- a/src/bitpacked_kmer_sorting/kmer_splitter.rs
+++ b/src/bitpacked_kmer_sorting/kmer_splitter.rs
@@ -3,7 +3,7 @@ use super::kmer_chunk::KmerChunk;
 use crate::tempfile::{TempFile, TempFileManager};
 use crate::util::DNA_ALPHABET;
 use std::io::{BufWriter, Seek, Write};
-use std::thread;
+use std::borrow::BorrowMut;
 
 fn colex_sorted_binmers(bin_prefix_len: usize) -> Vec<Vec<u8>> {
     let mut binmers = Vec::<Vec<u8>>::new();
@@ -31,133 +31,79 @@ pub fn split_to_bins<const B: usize, IN: crate::SeqStream + Send>(mut seqs: IN,
     // b = m / (64bt)
 
     // Wrap to scope to be able to borrow seqs for the producer thread even when it's not 'static.
-    std::thread::scope(|scope| {
-
-        let bin_prefix_len = 3_usize; // If you update this you must update all the logic below
-        let n_bins = (4_usize).pow(bin_prefix_len as u32); // 64
-        let producer_buf_size = 1_000_000_usize; // TODO: respect this
-        let encoder_bin_buf_size = mem_gb * (1_usize << 30) / ((n_bins * LongKmer::<B>::byte_size()) * n_threads);
-
-        log::info!("Splitting k-mers into {} bins", n_bins);
-        log::info!("Bin buffer size: {}", encoder_bin_buf_size);
+    let bin_prefix_len = 3_usize; // If you update this you must update all the logic below
+    let n_bins = (4_usize).pow(bin_prefix_len as u32); // 64
+    let mem_gb = mem_gb as usize * (1_usize << 30) as usize;
+    let encoder_bin_buf_size = mem_gb / ((n_bins as usize * LongKmer::<B>::byte_size() as usize) * n_threads as usize);
+
+    log::info!("Splitting k-mers into {} bins", n_bins);
+    let mut bin_buffers = vec![Vec::<LongKmer::<B>>::new(); n_bins];
+    for buf in bin_buffers.iter_mut(){
+        buf.reserve_exact(encoder_bin_buf_size.try_into().unwrap());
+    }
 
-        use crossbeam::crossbeam_channel::bounded;
-        let (parser_out, encoder_in) = bounded(4);
-        let (encoder_out, writer_in) = bounded(4);
+    let mut buf = Vec::<Box<[u8]>>::new();
+    while let Some(seq) = seqs.stream_next() {
+	let mut seq_copy = seq.to_owned();
+        seq_copy.reverse(); // Reverse to get colex sorting
+	buf.push(seq_copy.into_boxed_slice());
+    }
 
-        // Create producer
-        let producer_handle = scope.spawn(move || {
-            let mut buf = Vec::<Box<[u8]>>::new();
-            let mut current_total_buffer_size = 0_usize;
-            
-            while let Some(seq) = seqs.stream_next(){
-                current_total_buffer_size += seq.len();
-                let mut seq_copy = seq.to_owned();
-                seq_copy.reverse(); // Reverse to get colex sorting
-                buf.push(seq_copy.into_boxed_slice());
-                if current_total_buffer_size > producer_buf_size{
-                    let mut sendbuf = Vec::<Box<[u8]>>::new();
-                    std::mem::swap(&mut sendbuf, &mut buf);
-                    parser_out.send(sendbuf).unwrap();
-                    current_total_buffer_size = 0;
-                }
+    for seq in &buf {
+	for kmer in seq.windows(k){
+            match LongKmer::<B>::from_ascii(kmer) {
+		Ok(kmer) => {
+                    let bin_id = kmer.get_from_left(0) as usize * 16 + kmer.get_from_left(1) as usize * 4 + kmer.get_from_left(2) as usize; // Interpret nucleotides in base-4
+                    bin_buffers[bin_id].push(kmer);
+		}
+		Err(KmerEncodingError::InvalidNucleotide(_)) => (), // Ignore
+		Err(KmerEncodingError::TooLong(_)) => panic!("k = {} is too long", k),
             }
-            
-            parser_out.send(buf).unwrap();
-            drop(parser_out);
-        });
-
-        // Create encoder-splitters
-        let mut encoder_handles = Vec::<thread::JoinHandle::<()>>::new();
-        for _ in 0..n_threads{
-            let receiver_clone = encoder_in.clone();
-            let sender_clone = encoder_out.clone();
-            encoder_handles.push(std::thread::spawn(move || {
-                let mut bin_buffers = vec![Vec::<LongKmer::<B>>::new(); n_bins];
-                for buf in bin_buffers.iter_mut(){
-                    buf.reserve_exact(encoder_bin_buf_size);
-                }
-                while let Ok(batch) = receiver_clone.recv(){
-                    for seq in batch{
-                        for kmer in seq.windows(k){
-                            match LongKmer::<B>::from_ascii(kmer) {
-                                Ok(kmer) => {
-                                    let bin_id = kmer.get_from_left(0) as usize * 16 + kmer.get_from_left(1) as usize * 4 + kmer.get_from_left(2) as usize; // Interpret nucleotides in base-4
-                                    bin_buffers[bin_id].push(kmer);
-                                    if bin_buffers[bin_id].len() == encoder_bin_buf_size{
-                                        if dedup_batches{
-                                            bin_buffers[bin_id].sort_unstable();
-                                            bin_buffers[bin_id].dedup();
-                                        }
-                                        sender_clone.send(bin_buffers[bin_id].clone()).unwrap();
-                                        bin_buffers[bin_id].clear();
-                                    }
-                                }
-                                Err(KmerEncodingError::InvalidNucleotide(_)) => (), // Ignore
-                                Err(KmerEncodingError::TooLong(_)) => panic!("k = {} is too long", k),
-                            }        
-                        }
-                    }
-                }
+	}
+    }
 
-                // Send remaining buffers
-                for mut b in bin_buffers{
-                    if dedup_batches{
-                        b.sort_unstable();
-                        b.dedup();
-                    }
-                    sender_clone.send(b).unwrap();
-                }
-            }));
+    // Send remaining buffers
+    if dedup_batches {
+        for b in &mut bin_buffers{
+            b.sort_unstable();
+            b.dedup();
         }
+    }
 
-        // Create writers
-        let mut bin_writers = 
-            Vec::<std::io::BufWriter::<TempFile>>::new();
+    // Create writers
+    let mut bin_writers = Vec::<std::io::BufWriter::<TempFile>>::new();
 
-        for binmer in colex_sorted_binmers(bin_prefix_len) {
-            let name_prefix = format!("sbwt-temp-{}-", String::from_utf8(binmer).unwrap());
-            let f = temp_file_manager.create_new_file(&name_prefix, 8, ".bin");
-            bin_writers.push(BufWriter::new(f));
-        }
+    for binmer in colex_sorted_binmers(bin_prefix_len) {
+        let name_prefix = format!("sbwt-temp-{}-", String::from_utf8(binmer).unwrap());
+        let f = temp_file_manager.create_new_file(&name_prefix, 8, ".bin");
+        bin_writers.push(BufWriter::new(f));
+    }
 
 
-        let writer_handle = thread::spawn( move || {
-            while let Ok(batch) = writer_in.recv(){
-                if !batch.is_empty() {
-                    let bin_id = batch[0].get_from_left(0) as usize * 16 + batch[0].get_from_left(1) as usize * 4 + batch[0].get_from_left(2) as usize; // Intepret nucleotides in base-4
-                    let bin_file = &mut bin_writers[bin_id];
-                    for kmer in batch{
-                        kmer.serialize(bin_file).unwrap(); // Todo: write all at once
-                    }
-                }
+    bin_buffers.iter().for_each(|batch| {
+        if !batch.is_empty() {
+            let bin_id = batch[0].get_from_left(0) as usize * 16 + batch[0].get_from_left(1) as usize * 4 + batch[0].get_from_left(2) as usize; // Intepret nucleotides in base-4
+            let bin_file = &mut bin_writers[bin_id];
+            for kmer in batch{
+                kmer.serialize(bin_file).unwrap(); // Todo: write all at once
             }
-            bin_writers
-        });
-
-        producer_handle.join().unwrap();
-        drop(encoder_in); // Close the channel
-        for h in encoder_handles{
-            h.join().unwrap();
         }
-        drop(encoder_out); // Close the channel
+    });
 
-        // Return the TempFiles
-        let writers = writer_handle.join().unwrap();
-        let mut writers: Vec<TempFile> = writers.into_iter().map(|w| w.into_inner().unwrap()).collect();
-        for w in writers.iter_mut(){
-            w.file.seek(std::io::SeekFrom::Start(0)).unwrap();
-        }
-        writers
+    // Return the TempFiles
+    let mut writers: Vec<TempFile> = bin_writers.into_iter().map(|w| w.into_inner().unwrap()).collect();
+    for w in writers.iter_mut(){
+        w.file.seek(std::io::SeekFrom::Start(0)).unwrap();
+    }
+    writers
 
-    })
 }
 
 // Overwrite the files with sorted and deduplicates files. Returns back the files after overwriting.
-pub fn par_sort_and_dedup_bin_files<const B: usize>(bin_files: Vec<TempFile>, mem_gb: usize, n_threads: usize) -> Vec<TempFile> {
+pub fn par_sort_and_dedup_bin_files<const B: usize>(bin_files: &mut Vec<TempFile>, mem_gb: usize, n_threads: usize) {
 
-    let filesizes = bin_files.iter().map(|f| f.path.metadata().unwrap().len() as usize).collect::<Vec<usize>>();
-    let mut files_and_sizes = bin_files.into_iter().enumerate().map(|(i, f)| (f, filesizes[i], i)).collect::<Vec<(TempFile, usize, usize)>>();
+    let filesizes = bin_files.iter().map(|f| f.avail_in() as usize).collect::<Vec<usize>>();
+    let mut files_and_sizes = bin_files.into_iter().enumerate().map(|(i, f)| (f, filesizes[i], i)).collect::<Vec<(&mut TempFile, usize, usize)>>();
         
     files_and_sizes.sort_by_key(|(_, size, _)| *size);
 
@@ -165,86 +111,20 @@ pub fn par_sort_and_dedup_bin_files<const B: usize>(bin_files: Vec<TempFile>, me
 
     log::info!("Sorting k-mer bins");
 
-    use crossbeam::unbounded;
-
-    // A work queue
-    let (queue_sender, queue_recvr) = unbounded::<(TempFile, usize, usize)>(); // File, size, index
-
-    // A queue to notify the producer that a bin has been processed.
-    // The usize in the channel is the size of the bin that was processed.
-    let (producer_notify, producer_recv_notify) = unbounded::<usize>();
-
-    // Wrap in mutex to share between threads
-    let mut total_size_in_processing = 0_usize;
-
-    // Start the producer
-    let producer_handle = thread::spawn(move || {
-        while !files_and_sizes.is_empty() {
-            // Push as much work to the queue as possible
-            while !files_and_sizes.is_empty(){    
-                let s = files_and_sizes.last().unwrap().1; // Size
-                if total_size_in_processing == 0 || total_size_in_processing + s <= max_mem {
-                    let (f,s,i) = files_and_sizes.pop().unwrap();
-                    queue_sender.send((f, s, i)).unwrap();
-                    total_size_in_processing += s;
-                } else {
-                    break;
-                }
-            }
-
-            let s_done = producer_recv_notify.recv().unwrap(); // Wait for a notification
-            total_size_in_processing -= s_done;
-        }
-
-        // All files have been pushed to the channel
-        drop(queue_sender); // Close the channel
-    });
-
-    let mut consumer_handles = Vec::<thread::JoinHandle<Vec::<(TempFile, usize)>>>::new();
-
-    // Spawn consumers
-    for _ in 0..n_threads{
-        let recv_clone = queue_recvr.clone();
-        let producer_notify = producer_notify.clone();
-
-        consumer_handles.push(std::thread::spawn( move || {
-            let mut processed_files = Vec::<(TempFile, usize)>::new(); // File, index
-            while let Ok((mut f, s, i)) = recv_clone.recv(){
-                // Using debug log level as a more verbose info level
-                log::debug!("Sorting bin {} of size {}", f.path.display(), s);
-                let mut reader = std::io::BufReader::new(&f.file);
-                let chunk = KmerChunk::<B>::load(&mut reader).unwrap();
+    files_and_sizes.iter_mut().for_each(|(f, _s, _i)| {
+        // Using debug log level as a more verbose info level
+        let mut reader = std::io::BufReader::new(f.file.borrow_mut());
+        let chunk = KmerChunk::<B>::load(&mut reader).unwrap();
         
-                let mut chunk = chunk.sort();
-                chunk.dedup();
-
-                // Overwrite the file and seek to start
-                f.file.set_len(0).unwrap();
-                f.file.seek(std::io::SeekFrom::Start(0)).unwrap();
-                let chunk_out = std::io::BufWriter::new(&mut f);
-                chunk.serialize(chunk_out).unwrap();
-                f.flush().unwrap();
-                f.file.seek(std::io::SeekFrom::Start(0)).unwrap();
-
-                // Notify the producer that s bytes have been processed and
-                // new work can possibly be pushed to the queue.
-                let _ = producer_notify.send(s); // This may fail if the producer has already exited. That is ok.
-
-                processed_files.push((f,i));
-            }
-            processed_files // Return to owner
-        }));
-    }
-
-    let mut processed_files = Vec::<(TempFile, usize)>::new();
-    producer_handle.join().unwrap();
-    for h in consumer_handles{
-        processed_files.extend(h.join().unwrap());
-    }
-    processed_files.sort_by(|(_, i1), (_, i2)| i1.cmp(i2));
-
-    processed_files.into_iter().map(|(f,_)| f).collect() // Return to owner
-
+        let mut chunk = chunk.sort();
+        chunk.dedup();
+
+        // Overwrite the file and seek to start
+	f.file = std::io::Cursor::new(Vec::new());
+        let chunk_out = std::io::BufWriter::new(f.file.borrow_mut());
+        chunk.serialize(chunk_out).unwrap();
+        f.file.seek(std::io::SeekFrom::Start(0)).unwrap();
+    });
 }
 
 // The original files are deleted
diff --git a/src/bitpacked_kmer_sorting/kmer_splitter.rs~ b/src/bitpacked_kmer_sorting/kmer_splitter.rs~
new file mode 100644
index 0000000..68b0da3
--- /dev/null
+++ b/src/bitpacked_kmer_sorting/kmer_splitter.rs~
@@ -0,0 +1,148 @@
+use super::kmer::*;
+use super::kmer_chunk::KmerChunk;
+use crate::tempfile::{TempFile, TempFileManager};
+use crate::util::DNA_ALPHABET;
+use std::io::{BufWriter, Seek, Write};
+use std::borrow::BorrowMut;
+
+fn colex_sorted_binmers(bin_prefix_len: usize) -> Vec<Vec<u8>> {
+    let mut binmers = Vec::<Vec<u8>>::new();
+    for i in 0..(4_usize.pow(bin_prefix_len as u32)){
+        let mut binmer = Vec::<u8>::new();
+        let mut j = i;
+        for _ in 0..bin_prefix_len{
+            binmer.push(DNA_ALPHABET[j % 4]);
+            j /= 4;
+        }
+        binmers.push(binmer);
+    }
+    binmers
+}
+
+pub fn split_to_bins<const B: usize, IN: crate::SeqStream + Send>(mut seqs: IN, k: usize, mem_gb: usize, n_threads: usize, dedup_batches: bool, temp_file_manager: &mut TempFileManager) -> Vec<TempFile>{
+
+    // Suppose we have a memory budget of m bytes and t threads.
+    // Suppose each k-mer takes s bytes and there are 64 bins.
+    // Let b be the number of k-mers in each splitter thread bin buffer.
+    // A splitter thread uses 64bs bytes
+    // In total the splitter threads use 64bst threads.
+    // So, we need:
+    // 64bbt = m
+    // b = m / (64bt)
+
+    // Wrap to scope to be able to borrow seqs for the producer thread even when it's not 'static.
+    let bin_prefix_len = 3_usize; // If you update this you must update all the logic below
+    let n_bins = (4_usize).pow(bin_prefix_len as u32); // 64
+    let mem_gb = (mem_gb as usize * (1_usize << 30) as usize);
+    let encoder_bin_buf_size = mem_gb / ((n_bins as usize * LongKmer::<B>::byte_size() as usize) * n_threads as usize);
+
+    log::info!("Splitting k-mers into {} bins", n_bins);
+    let mut bin_buffers = vec![Vec::<LongKmer::<B>>::new(); n_bins];
+    for buf in bin_buffers.iter_mut(){
+        buf.reserve_exact(encoder_bin_buf_size.try_into().unwrap());
+    }
+
+    let mut buf = Vec::<Box<[u8]>>::new();
+    while let Some(seq) = seqs.stream_next() {
+	let mut seq_copy = seq.to_owned();
+        seq_copy.reverse(); // Reverse to get colex sorting
+	buf.push(seq_copy.into_boxed_slice());
+    }
+
+    for seq in &buf {
+	for kmer in seq.windows(k){
+            match LongKmer::<B>::from_ascii(kmer) {
+		Ok(kmer) => {
+                    let bin_id = kmer.get_from_left(0) as usize * 16 + kmer.get_from_left(1) as usize * 4 + kmer.get_from_left(2) as usize; // Interpret nucleotides in base-4
+                    bin_buffers[bin_id].push(kmer);
+		}
+		Err(KmerEncodingError::InvalidNucleotide(_)) => (), // Ignore
+		Err(KmerEncodingError::TooLong(_)) => panic!("k = {} is too long", k),
+            }
+	}
+    }
+
+    // Send remaining buffers
+    if dedup_batches {
+        for b in &mut bin_buffers{
+            b.sort_unstable();
+            b.dedup();
+        }
+    }
+
+    // Create writers
+    let mut bin_writers = Vec::<std::io::BufWriter::<TempFile>>::new();
+
+    for binmer in colex_sorted_binmers(bin_prefix_len) {
+        let name_prefix = format!("sbwt-temp-{}-", String::from_utf8(binmer).unwrap());
+        let f = temp_file_manager.create_new_file(&name_prefix, 8, ".bin");
+        bin_writers.push(BufWriter::new(f));
+    }
+
+
+    bin_buffers.iter().for_each(|batch| {
+        if !batch.is_empty() {
+            let bin_id = batch[0].get_from_left(0) as usize * 16 + batch[0].get_from_left(1) as usize * 4 + batch[0].get_from_left(2) as usize; // Intepret nucleotides in base-4
+            let bin_file = &mut bin_writers[bin_id];
+            for kmer in batch{
+                kmer.serialize(bin_file).unwrap(); // Todo: write all at once
+            }
+        }
+    });
+
+    // Return the TempFiles
+    let mut writers: Vec<TempFile> = bin_writers.into_iter().map(|w| w.into_inner().unwrap()).collect();
+    for w in writers.iter_mut(){
+        w.file.seek(std::io::SeekFrom::Start(0)).unwrap();
+    }
+    writers
+
+}
+
+// Overwrite the files with sorted and deduplicates files. Returns back the files after overwriting.
+pub fn par_sort_and_dedup_bin_files<const B: usize>(bin_files: &mut Vec<TempFile>, mem_gb: usize, n_threads: usize) {
+
+    let filesizes = bin_files.iter().map(|f| f.avail_in() as usize).collect::<Vec<usize>>();
+    let mut files_and_sizes = bin_files.into_iter().enumerate().map(|(i, f)| (f, filesizes[i], i)).collect::<Vec<(&mut TempFile, usize, usize)>>();
+        
+    files_and_sizes.sort_by_key(|(_, size, _)| *size);
+
+    let max_mem = mem_gb * (1_usize << 30);
+
+    log::info!("Sorting k-mer bins");
+
+    files_and_sizes.iter_mut().for_each(|(f, _s, _i)| {
+        // Using debug log level as a more verbose info level
+        let mut reader = std::io::BufReader::new(f.file.borrow_mut());
+        let chunk = KmerChunk::<B>::load(&mut reader).unwrap();
+        
+        let mut chunk = chunk.sort();
+        chunk.dedup();
+
+        // Overwrite the file and seek to start
+	f.file = std::io::Cursor::new(Vec::new());
+        let chunk_out = std::io::BufWriter::new(f.file.borrow_mut());
+        chunk.serialize(chunk_out).unwrap();
+        f.file.seek(std::io::SeekFrom::Start(0)).unwrap();
+    });
+}
+
+// The original files are deleted
+pub fn concat_files(infiles: Vec<TempFile>, out_writer: &mut impl std::io::Write){
+    let mut bw = BufWriter::new(out_writer);
+    for mut fp in infiles {
+        let mut reader = std::io::BufReader::new(&mut fp.file);
+        std::io::copy(&mut reader, &mut bw).unwrap();
+        // fp is dropped here, which deletes the file
+    }
+    bw.flush().unwrap();
+}
+
+mod tests {
+    #[test]
+    fn test_colex_sorted_binmers(){
+        let binmers = super::colex_sorted_binmers(2);
+        let ans = vec![b"AA", b"CA", b"GA", b"TA", b"AC", b"CC", b"GC", b"TC", b"AG", b"CG", b"GG", b"TG", b"AT", b"CT", b"GT", b"TT"];
+        assert_eq!(binmers, ans);
+    }
+}
diff --git a/src/bitpacked_kmer_sorting/mod.rs b/src/bitpacked_kmer_sorting/mod.rs
index f4ec05d..ecabbf2 100644
--- a/src/bitpacked_kmer_sorting/mod.rs
+++ b/src/bitpacked_kmer_sorting/mod.rs
@@ -14,66 +14,62 @@ use crate::{sbwt::{PrefixLookupTable, SbwtIndex}, streaming_index::LcsArray, sub
 /// user-friendly interface. B is the number u64 words in a k-mer.
 pub fn build_with_bitpacked_kmer_sorting<const B: usize, IN: crate::SeqStream + Send, SS: SubsetSeq + Send>(seqs: IN, k: usize, mem_gb: usize, n_threads: usize, dedup_batches: bool, build_lcs: bool, temp_file_manager: &mut TempFileManager) -> (SbwtIndex::<SS>, Option<LcsArray>) {
 
-    let thread_pool = rayon::ThreadPoolBuilder::new().num_threads(n_threads).build().unwrap();
+    let sigma = DNA_ALPHABET.len();
 
-    thread_pool.install(||{
-        let sigma = DNA_ALPHABET.len(); 
+    log::info!("Splitting k-mers into bins");
+    let mut bin_files = kmer_splitter::split_to_bins::<B, IN>(seqs, k, mem_gb, n_threads, dedup_batches, temp_file_manager);
 
-        log::info!("Splitting k-mers into bins");
-        let bin_files = kmer_splitter::split_to_bins::<B, IN>(seqs, k, mem_gb, n_threads, dedup_batches, temp_file_manager);
+    log::info!("Sorting and deduplicating bins");
+    kmer_splitter::par_sort_and_dedup_bin_files::<B>(&mut bin_files, mem_gb, n_threads);
 
-        log::info!("Sorting and deduplicating bins");
-        let bin_files = kmer_splitter::par_sort_and_dedup_bin_files::<B>(bin_files, mem_gb, n_threads);
+    let mut kmers_file = temp_file_manager.create_new_file("kmers-", 10, ".bin");
+    kmer_splitter::concat_files(bin_files, &mut kmers_file.file);
+    kmers_file.file.seek(std::io::SeekFrom::Start(0)).unwrap();
 
-        let mut kmers_file = temp_file_manager.create_new_file("kmers-", 10, ".bin");
-        kmer_splitter::concat_files(bin_files, &mut kmers_file.file);
-        kmers_file.file.seek(std::io::SeekFrom::Start(0)).unwrap();
+    let n_kmers = kmers_file.avail_in() / kmer::LongKmer::<B>::byte_size();
 
-        let n_kmers = std::fs::metadata(&kmers_file.path).unwrap().len() as usize / kmer::LongKmer::<B>::byte_size();
+    log::info!("{} distinct k-mers found", n_kmers);
+    let required_dummies = dummies::get_sorted_dummies::<B>(&mut kmers_file, sigma, k, temp_file_manager);
 
-        log::info!("{} distinct k-mers found", n_kmers);
+    let n = n_kmers + required_dummies.len();
 
-        let required_dummies = dummies::get_sorted_dummies::<B>(&kmers_file.path, sigma, k, temp_file_manager);
-
-        log::info!("{} dummy nodes needed", required_dummies.len());
-
-        let n = n_kmers + required_dummies.len();
-
-        // Write dummies to disk
-        let mut dummy_file = temp_file_manager.create_new_file("dummies-", 10, ".bin");
-        dummies::write_to_disk(required_dummies, &mut dummy_file.file);
-        
-        log::info!("Constructing the sbwt subset sequence");
-
-        let char_cursors = cursors::init_char_cursors::<B>(&dummy_file.path, &kmers_file.path, k, sigma);
-
-        let global_cursor = cursors::DummyNodeMerger::new(
-            std::io::BufReader::new(std::fs::File::open(&dummy_file.path).unwrap()),
-            std::io::BufReader::new(std::fs::File::open(&kmers_file.path).unwrap()),
-            k,
-        );
-
-        let (rawrows, lcs) = cursors::build_sbwt_bit_vectors(global_cursor, char_cursors, n, k, sigma, build_lcs);
-
-        // Create the C array
-        #[allow(non_snake_case)] // C-array is an established convention in BWT indexes
-        let C: Vec<usize> = crate::util::get_C_array(&rawrows);
-
-        log::info!("Building the subset rank structure");
-        let mut subsetseq = SS::new_from_bit_vectors(rawrows.into_iter().map(simple_sds_sbwt::bit_vector::BitVector::from).collect());
-        subsetseq.build_rank();
-        let n_sets = subsetseq.len();
-        let (mut index, lcs) = (SbwtIndex::<SS>::from_components(
-            subsetseq,
-            n_kmers,
-            k,
-            C,
-            PrefixLookupTable::new_empty(n_sets))
-        , lcs.map(LcsArray::new));
-
-        let lut = PrefixLookupTable::new(&index, 8);
-        index.set_lookup_table(lut);
-        (index, lcs)
-    })
+    // Write dummies to disk
+    let mut dummy_file = temp_file_manager.create_new_file("dummies-", 10, ".bin");
+    dummies::write_to_disk(required_dummies, &mut dummy_file);
     
-}
\ No newline at end of file
+    log::info!("Constructing the sbwt subset sequence");
+
+    let char_cursors = cursors::init_char_cursors::<B>(&mut dummy_file, &mut kmers_file, k, sigma);
+
+    dummy_file.file.seek(std::io::SeekFrom::Start(0)).unwrap();
+    kmers_file.file.seek(std::io::SeekFrom::Start(0)).unwrap();
+
+    let global_cursor = cursors::DummyNodeMerger::new(
+        &mut dummy_file,
+        &mut kmers_file,
+        k,
+    );
+
+    let (rawrows, lcs) = cursors::build_sbwt_bit_vectors(global_cursor, char_cursors, n, k, sigma, build_lcs);
+
+    // Create the C array
+    #[allow(non_snake_case)] // C-array is an established convention in BWT indexes
+    let C: Vec<usize> = crate::util::get_C_array(&rawrows);
+
+    log::info!("Building the subset rank structure");
+    let mut subsetseq = SS::new_from_bit_vectors(rawrows.into_iter().map(simple_sds_sbwt::bit_vector::BitVector::from).collect());
+    subsetseq.build_rank();
+    let n_sets = subsetseq.len();
+    let (mut index, lcs) = (SbwtIndex::<SS>::from_components(
+        subsetseq,
+        n_kmers,
+        k,
+        C,
+        PrefixLookupTable::new_empty(n_sets))
+			    , lcs.map(LcsArray::new));
+
+    let lut = PrefixLookupTable::new(&index, 8);
+    index.set_lookup_table(lut);
+    (index, lcs)
+
+}
diff --git a/src/builder.rs b/src/builder.rs
index 1384d42..cf47cbb 100644
--- a/src/builder.rs
+++ b/src/builder.rs
@@ -51,7 +51,6 @@ pub trait SbwtConstructionAlgorithm {
 pub struct BitPackedKmerSorting{
     mem_gb: usize,
     dedup_batches: bool,
-    temp_dir: std::path::PathBuf,
 }
 
 impl BitPackedKmerSorting {
@@ -61,7 +60,7 @@ impl BitPackedKmerSorting {
     /// - do not deduplicate k-mer batches before sorting.
     /// - use the current directory as the temporary directory.
     pub fn new() -> Self {
-        Self{mem_gb: 4, dedup_batches: false, temp_dir: std::path::PathBuf::from_str(".").unwrap()}
+        Self{mem_gb: 4, dedup_batches: false}
     }
 
     /// Set the amount of memory to use in gigabytes. This is not strictly enforced, but the algorithm will try to stay within this limit.
@@ -75,20 +74,13 @@ impl BitPackedKmerSorting {
         self.dedup_batches = enable;
         self
     }
-
-    /// Set the temporary directory where the algorithm can store temporary files.
-    pub fn temp_dir(mut self, temp_dir: &std::path::Path) -> Self {
-        self.temp_dir = temp_dir.to_path_buf();
-        std::fs::create_dir_all(&self.temp_dir).unwrap();
-        self
-    }
 }
 
 impl SbwtConstructionAlgorithm for BitPackedKmerSorting {
     fn run<SS: SeqStream + Send>(self, input: SS, k: usize, n_threads: usize, build_lcs: bool) -> (SbwtIndex<SubsetMatrix>, Option<LcsArray>) {
         let mem_gb = self.mem_gb;
         let dedup_batches = self.dedup_batches;
-        let mut temp_file_manager = crate::tempfile::TempFileManager::new(&self.temp_dir);
+        let mut temp_file_manager = crate::tempfile::TempFileManager::new();
         match k {
             0..=32 => {
                 crate::bitpacked_kmer_sorting::build_with_bitpacked_kmer_sorting::<1,_,SubsetMatrix>(input, k, mem_gb, n_threads, dedup_batches, build_lcs, &mut temp_file_manager)
diff --git a/src/lib.rs b/src/lib.rs
index 2aafdc8..3d0ae7d 100644
--- a/src/lib.rs
+++ b/src/lib.rs
@@ -33,8 +33,7 @@
 //!     .k(6).n_threads(4).build_lcs(true).add_rev_comp(true)
 //!     .algorithm(BitPackedKmerSorting::new()
 //!         .mem_gb(2)
-//!         .dedup_batches(false)
-//!         .temp_dir(Path::new("./temp")))
+//!         .dedup_batches(false))
 //!     .run(seq_stream);
 //!
 //! // Query a k-mer
diff --git a/src/tempfile.rs b/src/tempfile.rs
index 5ebfcc9..9aa51fa 100644
--- a/src/tempfile.rs
+++ b/src/tempfile.rs
@@ -1,133 +1,93 @@
-use std::path::{Path, PathBuf};
-
-use rand::{Rng, SeedableRng};
+use std::io::Cursor;
+use std::path::{Path};
 
 /// A simple struct to manage temporary files.
 /// All files will be created in the directory specified in the struct.
 pub struct TempFileManager {
-    directory: PathBuf,
-    rng: rand::rngs::StdRng,
 }
 
 /// A struct encapsulating a std::fs::File and its path.
 /// When the TempFile is dropped, the file is deleted.
-#[derive(Debug)]
+#[derive(Debug, Default)]
 pub struct TempFile {
-    pub path: PathBuf,
-    pub file: std::fs::File,
+    pub file: Cursor<Vec<u8>>,
 }
 
 impl Drop for TempFile {
     fn drop(&mut self) {
-        log::trace!("Dropping temp file {}", self.path.display());
-        std::fs::remove_file(&self.path).unwrap();
+	self.file.get_mut().clear();
     }
 }
 
 impl std::io::Write for TempFile {
     fn write(&mut self, buf: &[u8]) -> std::io::Result<usize> {
-        self.file.write(buf)
+	self.file.write(buf)
     }
 
     fn flush(&mut self) -> std::io::Result<()> {
-        self.file.flush()
+	self.file.flush()
     }
 }
 
 impl std::io::Read for TempFile {
     fn read(&mut self, buf: &mut [u8]) -> std::io::Result<usize> {
-        self.file.read(buf)
+	self.file.read(buf)
     }
 }
 
-impl TempFileManager {
-
-    fn get_random_filename(&mut self, prefix: &str, random_infix_length: usize, suffix: &str) -> PathBuf {
-
-            let mut random_part = String::new();
-            for _ in 0..random_infix_length {
-                let r = self.rng.gen_range(0, 26);
-                let c = b'a' + r; // Random character from a..z
-                random_part.push(c as char);
-            }
-
-            let mut fname = String::new();
-            fname.push_str(prefix);
-            fname.push_str(&random_part);
-            fname.push_str(suffix);
-
-            let mut path = self.directory.clone();
-            path.push(fname);
-            path
+impl TempFile {
+    pub fn avail_in(&self) -> usize {
+	return self.file.get_ref().len();
     }
+}
 
-    pub fn new(directory: &Path) -> Self {
-        let seed = rand::thread_rng().gen();
-        let rng = rand::rngs::StdRng::seed_from_u64(seed);
+impl TempFileManager {
 
-        std::fs::create_dir_all(directory).unwrap();
-        Self {directory: directory.to_path_buf(), rng}
+    pub fn new() -> Self {
+        Self{}
     }
 
     // Creates a new temp file with filename with format:
     // self.directory / prefix + random_infix + suffix.
     // &self is taken as mutable because we use an RNG to generate the infix. 
-    pub fn create_new_file(&mut self, prefix: &str, infix_length: usize, suffix: &str) -> TempFile {
-
-        let mut path = self.get_random_filename(prefix, infix_length, suffix);
-        let mut file = std::fs::File::create_new(&path);
-
-        while let Err(e) = file {
-            match e.kind() {
-                std::io::ErrorKind::AlreadyExists => {
-                    // Try again
-                    log::warn!("Temporary filename collision {}, trying again...", path.display());
-                    path = self.get_random_filename(prefix, infix_length, suffix);
-                    file = std::fs::File::create_new(&path);
-
-                },
-                _ => panic!("Error creating temp file: {} {}", path.display(), e),
-            }
-        }
-
-        log::trace!("Creating temp file {}", path.display());
-        TempFile {path, file: file.unwrap()}
+    pub fn create_new_file(&mut self, _prefix: &str, _infix_length: usize, _suffix: &str) -> TempFile {
+        TempFile {file: Cursor::new(Vec::new())}
     }
 }
 
-#[cfg(test)]
-mod tests {
-    use super::*;
+// #[cfg(test)]
+// mod tests {
+//     use super::*;
 
-    #[test_log::test]
-    fn test_tempfile() {
+//     #[test_log::test]
+//     fn test_tempfile() {
         
-        // Create a random prefix for our temp files. This is to avoid collisions
-        // with files created for previous runs of this test.
-        let seed = rand::thread_rng().gen();
-        let mut rng = rand::rngs::StdRng::seed_from_u64(seed);
-        let mut prefix = rng.gen_range(0, 1000000000).to_string();
-        prefix.push('-');
-
-        let mut temp_file_manager = TempFileManager::new(Path::new("/tmp"));
-
-        let mut files = Vec::<TempFile>::new();
-        let mut paths = Vec::<PathBuf>::new();
-
-        for _ in 0..26 { // Create filename collisions with very high probablity
-            let temp_file = temp_file_manager.create_new_file(&prefix, 1, ".txt");
-            paths.push(temp_file.path.clone());
-            files.push(temp_file);
-        }
-
-        for path in paths.iter() {
-            assert!(path.exists());
-        }
-
-        drop(files); // Should delete all our files
-
-        for path in paths.iter() {
-            assert!(!path.exists());
-        }
-    }
-}
\ No newline at end of file
+//         // Create a random prefix for our temp files. This is to avoid collisions
+//         // with files created for previous runs of this test.
+//         let seed = rand::thread_rng().gen();
+//         let mut rng = rand::rngs::StdRng::seed_from_u64(seed);
+//         let mut prefix = rng.gen_range(0, 1000000000).to_string();
+//         prefix.push('-');
+
+//         let mut temp_file_manager = TempFileManager::new(Path::new("/tmp"));
+
+//         let mut files = Vec::<TempFile>::new();
+//         let mut paths = Vec::<PathBuf>::new();
+
+//         for _ in 0..26 { // Create filename collisions with very high probablity
+//             let temp_file = temp_file_manager.create_new_file(&prefix, 1, ".txt");
+//             paths.push(temp_file.path.clone());
+//             files.push(temp_file);
+//         }
+
+//         for path in paths.iter() {
+//             assert!(path.exists());
+//         }
+
+//         drop(files); // Should delete all our files
+
+//         for path in paths.iter() {
+//             assert!(!path.exists());
+//         }
+//     }
+// }
diff --git a/src/util.rs b/src/util.rs
index 3efd5b1..5307f03 100644
--- a/src/util.rs
+++ b/src/util.rs
@@ -23,10 +23,24 @@ pub(crate) fn binary_search_leftmost_that_fulfills_pred<T, Access: Fn(usize) ->
     ans
 }
 
+// Searcher the range [0..n)
+// Return the index of the answer, or n if does not exist
+pub(crate) fn binary_search_leftmost_that_fulfills_pred_mut<T, Access: FnMut(usize) -> T, Pred: FnMut(T) -> bool>(mut access: Access, mut pred: Pred, n: usize) -> usize {
+    let mut ans = n;
+    let mut step = n;
+    while step > 0 {
+        while ans as isize - step as isize >= 0 && pred(access(ans-step)) {
+            ans -= step;
+        }
+        step /= 2;
+    }
+    ans
+}
+
 pub const DNA_ALPHABET: [u8; 4] = [b'A', b'C', b'G', b'T'];
 
 // This bit vector of length 256 marks the ascii values of these characters: acgtACGT
-const IS_DNA: BitArray<[usize; 4]> = bitarr![const 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0];
+const IS_DNA: BitArray<[u32; 8]> = bitarr![const u32, Lsb0; 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0];
 
 pub(crate) fn is_dna(c: u8) -> bool {
     IS_DNA[c as usize]
