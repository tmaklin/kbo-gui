diff --git a/Cargo.toml b/Cargo.toml
index 91e7ba9..521118a 100644
--- a/Cargo.toml
+++ b/Cargo.toml
@@ -1,72 +1,30 @@
-# THIS FILE IS AUTOMATICALLY GENERATED BY CARGO
-#
-# When uploading crates to the registry Cargo will automatically
-# "normalize" Cargo.toml files for maximal compatibility
-# with all versions of Cargo and also rewrite `path` dependencies
-# to registry (e.g., crates.io) dependencies.
-#
-# If you are reading this file be aware that the original Cargo.toml
-# will likely look very different (and much more reasonable).
-# See Cargo.toml.orig for the original contents.
-
 [package]
-edition = "2021"
-rust-version = "1.77"
 name = "sbwt"
 version = "0.3.2"
-authors = ["Jarno Niklas Alanko <alanko.jarno@gmail.com>"]
-description = "Indexing sets of DNA k-mers with the spectral Burrow-Wheeler transform."
-readme = "README.md"
+edition = "2021"
+rust-version = "1.77" # 1.77 needed for File::create_new
 license = "MIT"
+description = "Indexing sets of DNA k-mers with the spectral Burrow-Wheeler transform."
 repository = "https://github.com/jnalanko/sbwt-rs-cli/tree/master/api"
+authors = ["Jarno Niklas Alanko <alanko.jarno@gmail.com>"]
 
-[dependencies.bitvec]
-version = "1.0.1"
-
-[dependencies.byteorder]
-version = "1.5"
-
-[dependencies.chrono]
-version = "0.4"
-
-[dependencies.clap]
-version = "4.4"
-
-[dependencies.crossbeam]
-version = "0.5"
-
-[dependencies.embed-doc-image]
-version = "0.1.4"
-
-[dependencies.env_logger]
-version = "0.10"
-
-[dependencies.jseqio]
-version = "0.1.3"
-
-[dependencies.log]
-version = "0.4"
-
-[dependencies.num]
-version = "0.4"
-
-[dependencies.rand]
-version = "0.7"
-
-[dependencies.rayon]
-version = "1"
-
-[dependencies.read_exact]
-version = "0.0.1"
-
-[dependencies.simple-sds-sbwt]
-version = "0.3.1"
-
-[dependencies.test-log]
-version = "0.2"
-
-[dependencies.unitig_flipper]
-version = "0.1.0"
-
-[dev-dependencies.rand_chacha]
-version = "0.3.1"
+[dependencies]
+rayon = "1"
+num = "0.4"
+simple-sds-sbwt = "0.3.1"
+clap = "4.4"
+jseqio = "0.1.3"
+unitig_flipper = "0.1.0" 
+env_logger = "0.10"
+log = "0.4"
+crossbeam = "0.5"
+read_exact = "0.0.1"
+bitvec = "1.0.1"
+rand = "0.7"
+test-log = "0.2"
+byteorder = "1.5"
+chrono = "0.4"
+embed-doc-image = "0.1.4"
+
+[dev-dependencies]
+rand_chacha = "0.3.1" # Seeded rng in tests
diff --git a/src/bitpacked_kmer_sorting/cursors.rs b/src/bitpacked_kmer_sorting/cursors.rs
index d01ce41..cfbd05c 100644
--- a/src/bitpacked_kmer_sorting/cursors.rs
+++ b/src/bitpacked_kmer_sorting/cursors.rs
@@ -1,10 +1,12 @@
-use std::{io::{BufReader, Seek, Read}, fs::File, path::Path};
+use std::borrow::BorrowMut;
+use std::io::{Seek, Read};
 
 use simple_sds_sbwt::{ops::Access, raw_vector::AccessRaw};
 use std::io::SeekFrom;
 use std::cmp::min;
 use super::kmer::LongKmer;
-use crate::util::binary_search_leftmost_that_fulfills_pred;
+use crate::util::binary_search_leftmost_that_fulfills_pred_mut;
+use crate::tempfile::TempFile;
 
 pub struct DummyNodeMerger<R: std::io::Read, const B: usize> {
     dummy_reader: R, // Stream of k-mer objects
@@ -64,23 +66,6 @@ impl <R: std::io::Read, const B: usize> DummyNodeMerger<R, B> {
         }
     }
 
-    // TODO: this is stupid. The given positions are just for bookkeeping that the caller might use. They don't affect the
-    // cursor at all. Need to refactor.
-    pub fn new_with_initial_positions(mut dummy_reader: R, mut nondummy_reader: R, k: usize, dummy_position: usize, nondummy_position: usize) -> Self {
-        let dummy_kmer = Self::read_from_dummy_reader(&mut dummy_reader);
-        let nondummy_kmer = Self::read_from_non_dummy_reader(&mut nondummy_reader, k);
-
-        Self {
-            dummy_reader,
-            nondummy_reader,
-            dummy_kmer,
-            nondummy_kmer,
-            k,
-            dummy_position,
-            nondummy_position,
-        }
-    }
-
     pub fn peek(&self) -> Option<(LongKmer::<B>, u8)>{
         match (self.dummy_kmer, self.nondummy_kmer){
             (None, None) => None,
@@ -105,12 +90,47 @@ impl <R: std::io::Read, const B: usize> DummyNodeMerger<R, B> {
         self.dummy_position
     }
 
+    #[allow(dead_code)]
     pub fn nondummy_position(&self)  -> usize{
         self.nondummy_position
     }
 }
 
-impl<const B: usize> Iterator for DummyNodeMerger<BufReader<File>, B> {
+impl<const B: usize> Iterator for DummyNodeMerger<&mut TempFile, B> {
+    type Item = (LongKmer<B>, u8);
+
+    // Produces pairs (kmer, length)
+    fn next(&mut self) -> Option<(LongKmer::<B>, u8)> {
+        match (self.dummy_kmer, self.nondummy_kmer){
+            (None, None) => None,
+            (Some(dummy_kmer), None) => {
+                self.dummy_kmer = Self::read_from_dummy_reader(&mut self.dummy_reader);
+                self.dummy_position += 1;
+                Some(dummy_kmer)
+            },
+            (None, Some(nondummy_kmer)) => {
+                self.nondummy_kmer = Self::read_from_non_dummy_reader(&mut self.nondummy_reader, self.k);
+                self.nondummy_position += 1;
+                Some(nondummy_kmer)
+            },
+            (Some(dummy_kmer), Some(nondummy_kmer)) => {
+                if dummy_kmer < nondummy_kmer {
+                    self.dummy_kmer = Self::read_from_dummy_reader(&mut self.dummy_reader);
+                    self.dummy_position += 1;
+                    Some(dummy_kmer)
+                } else {
+                    self.nondummy_kmer = Self::read_from_non_dummy_reader(&mut self.nondummy_reader, self.k);
+                    self.nondummy_position += 1;
+                    Some(nondummy_kmer)
+                }
+            }
+        }
+    }
+
+}
+
+
+impl<const B: usize> Iterator for DummyNodeMerger<std::io::Cursor<Vec<u8>>, B> {
     type Item = (LongKmer<B>, u8);
 
     // Produces pairs (kmer, length)
@@ -143,28 +163,96 @@ impl<const B: usize> Iterator for DummyNodeMerger<BufReader<File>, B> {
 
 }
 
+impl<const B: usize> Iterator for DummyNodeMerger<&mut std::io::Cursor<Vec<u8>>, B> {
+    type Item = (LongKmer<B>, u8);
+
+    // Produces pairs (kmer, length)
+    fn next(&mut self) -> Option<(LongKmer::<B>, u8)> {
+        match (self.dummy_kmer, self.nondummy_kmer){
+            (None, None) => None,
+            (Some(dummy_kmer), None) => {
+                self.dummy_kmer = Self::read_from_dummy_reader(&mut self.dummy_reader);
+                self.dummy_position += 1;
+                Some(dummy_kmer)
+            },
+            (None, Some(nondummy_kmer)) => {
+                self.nondummy_kmer = Self::read_from_non_dummy_reader(&mut self.nondummy_reader, self.k);
+                self.nondummy_position += 1;
+                Some(nondummy_kmer)
+            },
+            (Some(dummy_kmer), Some(nondummy_kmer)) => {
+                if dummy_kmer < nondummy_kmer {
+                    self.dummy_kmer = Self::read_from_dummy_reader(&mut self.dummy_reader);
+                    self.dummy_position += 1;
+                    Some(dummy_kmer)
+                } else {
+                    self.nondummy_kmer = Self::read_from_non_dummy_reader(&mut self.nondummy_reader, self.k);
+                    self.nondummy_position += 1;
+                    Some(nondummy_kmer)
+                }
+            }
+        }
+    }
+}
+
+
+pub fn rewind_reader<const B: usize>(reader: &mut DummyNodeMerger<&mut TempFile, B>) {
+    match reader.dummy_reader.file.rewind() {
+        Ok(_) => {
+            // ok
+        },
+        Err(e) => panic!("Error while rewinding dummy reader cursor: {}", e),
+    }
+
+    match reader.nondummy_reader.file.rewind() {
+        Ok(_) => {
+            // ok
+        },
+        Err(e) => panic!("Error while rewinding nondummy reader cursor: {}", e),
+    }
+
+    reader.dummy_kmer = DummyNodeMerger::read_from_dummy_reader(reader.dummy_reader);
+    reader.nondummy_kmer = DummyNodeMerger::read_from_non_dummy_reader(reader.nondummy_reader, reader.k);
+    reader.dummy_position = 0;
+    reader.nondummy_position = 0;
+}
+
+pub fn reset_reader_position<const B: usize>(
+    reader: &mut DummyNodeMerger<&mut TempFile, B>,
+    dummy_reader_pos: u64,
+    nondummy_reader_pos: u64,
+    dummy_pos: usize,
+    nondummy_pos: usize
+) {
+        reader.dummy_reader.file.set_position(dummy_reader_pos);
+        reader.nondummy_reader.file.set_position(nondummy_reader_pos);
+        reader.dummy_kmer = DummyNodeMerger::read_from_dummy_reader(reader.dummy_reader);
+        reader.nondummy_kmer = DummyNodeMerger::read_from_non_dummy_reader(reader.nondummy_reader, reader.k);
+        reader.dummy_position = dummy_pos;
+        reader.nondummy_position = nondummy_pos;
+}
+
 // We take in Paths instead of a Files because we need multiple readers to the same files 
-pub fn init_char_cursors<const B: usize>(dummy_filepath: &Path, nondummy_filepath: &Path, k: usize, sigma: usize)
--> Vec<DummyNodeMerger<BufReader<File>, B>>{
-    let mut char_cursors = Vec::<DummyNodeMerger<BufReader<File>, B>>::new();
+pub fn init_char_cursor_positions<const B: usize>(dummy_file: &mut TempFile, nondummy_file: &mut TempFile, _k: usize, sigma: usize)
+-> Vec<((u64, u64), (u64, u64))>{
+    let mut char_cursor_positions = Vec::<((u64, u64), (u64, u64))>::new();
     for c in 0..(sigma as u8){
         log::trace!("Searching character {}", c);
 
-        let (dummy_reader, dummy_pos) = 
+        let (dummy_reader_pos, dummy_pos) =
         { // Seek in dummies
 
-            let dummy_file_len = std::fs::metadata(dummy_filepath).unwrap().len() as usize;
+            let dummy_file_len = dummy_file.avail_in() as usize;
             let dummy_record_len = LongKmer::<B>::byte_size() + 1; // Pairs (kmer, len byte)
             assert_eq!(dummy_file_len % dummy_record_len, 0);
     
             let access_fn = |pos| {
-                let mut f = File::open(dummy_filepath).unwrap();
-                f.seek(SeekFrom::Start(pos as u64 * dummy_record_len as u64)).unwrap();
-                let kmer = LongKmer::<B>::load(&mut f).unwrap().unwrap(); // Should never be none because we know the file length
+                dummy_file.file.seek(SeekFrom::Start(pos as u64 * dummy_record_len as u64)).unwrap();
+                let kmer = LongKmer::<B>::load(&mut dummy_file.file).unwrap().unwrap(); // Should never be none because we know the file length
 
                 // Read the length byte
                 let mut len_buf = [0_u8; 1];
-                f.read_exact(&mut len_buf).unwrap();
+                dummy_file.file.read_exact(&mut len_buf).unwrap();
                 let len = u8::from_le_bytes(len_buf);
                 (kmer, len)
             };
@@ -173,66 +261,59 @@ pub fn init_char_cursors<const B: usize>(dummy_filepath: &Path, nondummy_filepat
                 kmer.1 > 0 && kmer.0.get_from_left(0) >= c
             };
 
-            let start = binary_search_leftmost_that_fulfills_pred(
+            let start = binary_search_leftmost_that_fulfills_pred_mut(
                 access_fn, 
                 pred_fn, 
                 dummy_file_len / dummy_record_len);
 
-            let mut f = File::open(dummy_filepath).unwrap();
-            f.seek(SeekFrom::Start(start as u64 * dummy_record_len as u64)).unwrap();
-            (BufReader::new(f), start)
+            dummy_file.file.seek(SeekFrom::Start(start as u64 * dummy_record_len as u64)).unwrap();
+            (dummy_file.file.position(), start as u64)
         };
 
-        let (nondummy_reader, nondummy_pos) = 
+        let (nondummy_reader_pos, nondummy_pos) =
         { // Seek in nondummies
 
-            let nondummy_file_len = std::fs::metadata(nondummy_filepath).unwrap().len() as usize;
+            let nondummy_file_len = nondummy_file.avail_in() as usize;
             let nondummy_record_len = LongKmer::<B>::byte_size();
             assert_eq!(nondummy_file_len % nondummy_record_len, 0);
     
             let access_fn = |pos| {
-                let mut f = File::open(nondummy_filepath).unwrap();
-                f.seek(SeekFrom::Start(pos as u64 * nondummy_record_len as u64)).unwrap();
-                LongKmer::<B>::load(&mut f).unwrap().unwrap() // Should never be None because we know the file length
+		        nondummy_file.file.seek(SeekFrom::Start(pos as u64 * nondummy_record_len as u64)).unwrap();
+                LongKmer::<B>::load(&mut nondummy_file.file).unwrap().unwrap() // Should never be None because we know the file length
             };
 
             let pred_fn = |kmer: LongKmer::<B>| {
                 kmer.get_from_left(0) >= c
             };
 
-            let start = binary_search_leftmost_that_fulfills_pred(
+            let start = binary_search_leftmost_that_fulfills_pred_mut(
                 access_fn, 
                 pred_fn, 
                 nondummy_file_len / nondummy_record_len);
-        
-            let mut f = File::open(nondummy_filepath).unwrap();
-            f.seek(SeekFrom::Start(start as u64 * nondummy_record_len as u64)).unwrap();
-            (BufReader::new(f), start)
+
+            nondummy_file.file.seek(SeekFrom::Start(start as u64 * nondummy_record_len as u64)).unwrap();
+            (nondummy_file.file.position(), start as u64)
         };
 
-        let cursor = DummyNodeMerger::new_with_initial_positions(dummy_reader, nondummy_reader, k, dummy_pos, nondummy_pos);
-        char_cursors.push(cursor);
+        let cursor = ((dummy_reader_pos, dummy_pos), (nondummy_reader_pos, nondummy_pos));
+        char_cursor_positions.push(cursor);
     }
 
-    char_cursors
+    nondummy_file.file.seek(SeekFrom::Start(0)).unwrap();
+    char_cursor_positions
 
 }
 
 // Returns the SBWT bit vectors and optionally the LCS array
 pub fn build_sbwt_bit_vectors<const B: usize>(
-    global_cursor: DummyNodeMerger<BufReader<File>, B>, 
-    mut char_cursors: Vec<DummyNodeMerger<BufReader<File>, B>>, 
+    mut global_cursor: DummyNodeMerger<&mut TempFile, B>,
+    char_cursors: Vec<((u64, u64), (u64, u64))>,
     n: usize,
     k: usize, 
     sigma: usize,
     build_lcs: bool) -> (Vec<simple_sds_sbwt::raw_vector::RawVector>, Option<simple_sds_sbwt::int_vector::IntVector>)
 {
-
-    let mut rawrows = Vec::<simple_sds_sbwt::raw_vector::RawVector>::new();
-    for _ in 0..sigma {
-        rawrows.push(simple_sds_sbwt::raw_vector::RawVector::with_len(n, false));
-    }
-
+    let mut rawrows = vec![simple_sds_sbwt::raw_vector::RawVector::with_len(n, false); sigma];
     let mut lcs = if build_lcs { 
         // LCS values are between 0 and k-1
         assert!(k > 0);
@@ -242,19 +323,27 @@ pub fn build_sbwt_bit_vectors<const B: usize>(
         None 
     };
 
-    let mut prev_kmer = LongKmer::<B>::from_ascii(b"").unwrap();
-    let mut prev_len = 0_usize;
-    for (kmer_idx, (kmer, len)) in global_cursor.enumerate() {
-        // The k-mers enumerated are reversed
+    if build_lcs {
+        let mut prev_kmer = LongKmer::<B>::from_ascii(b"").unwrap();
+        let mut prev_len = 0_usize;
+        global_cursor.borrow_mut().enumerate().for_each(|(kmer_idx, (kmer, len))| {
+            if kmer_idx > 0 {
+                // The longest common suffix is the longest common prefix of reversed k-mers
+                let mut lcs_value = LongKmer::<B>::lcp(&prev_kmer, &kmer);
+                lcs_value = min(lcs_value, min(prev_len, len as usize));
+                lcs.as_mut().unwrap().set(kmer_idx, lcs_value as u64);
+            }
+            prev_kmer = kmer;
+            prev_len = len as usize;
+        });
+    }
 
-        if build_lcs && kmer_idx > 0 {
-            // The longest common suffix is the longest common prefix of reversed k-mers
-            let mut lcs_value = LongKmer::<B>::lcp(&prev_kmer, &kmer);
-            lcs_value = min(lcs_value, min(prev_len, len as usize));
-            lcs.as_mut().unwrap().set(kmer_idx, lcs_value as u64);
-        }
+    for c in 0..(sigma as u8) {
+
+        rewind_reader(&mut global_cursor);
 
-        for c in 0..(sigma as u8) {
+        let kmer_cs = global_cursor.borrow_mut().map(|(kmer, len)| {
+            // The k-mers enumerated are reversed
             let kmer_c = if len as usize == k {
                 (
                     kmer.clone()
@@ -266,73 +355,78 @@ pub fn build_sbwt_bit_vectors<const B: usize>(
             } else {
                 (kmer.clone().right_shift(1).set_from_left(0, c), len + 1) // Dummy
             };
-
-            while char_cursors[c as usize].peek().is_some() && char_cursors[c as usize].peek().unwrap() < kmer_c {
-                char_cursors[c as usize].next();
+            kmer_c
+        }).collect::<Vec<(LongKmer::<B>, u8)>>();
+
+        reset_reader_position(&mut global_cursor,
+                              char_cursors[c as usize].0.0,
+                              char_cursors[c as usize].1.0,
+                              char_cursors[c as usize].0.1 as usize,
+                              char_cursors[c as usize].1.1 as usize);
+
+        kmer_cs.iter().enumerate().for_each(|(kmer_idx, kmer_c)| {
+            while global_cursor.peek().is_some() && global_cursor.peek().unwrap() < *kmer_c {
+                global_cursor.next();
             }
 
-            if char_cursors[c as usize].peek().is_some() && char_cursors[c as usize].peek().unwrap() == kmer_c {
+            if global_cursor.peek().is_some() && global_cursor.peek().unwrap() == *kmer_c {
                 rawrows[c as usize].set_bit(kmer_idx, true);
-                char_cursors[c as usize].next();
+                global_cursor.next();
             }
-        }
-        prev_kmer = kmer;
-        prev_len = len as usize;
+        });
     }
 
     (rawrows, lcs)
 
 }
 
-#[cfg(test)]
-mod tests{
-
-    use std::io::Write;
-
-    use super::*;
-
-    #[test]
-    fn test_init_char_cursors(){
-        let nondummies = [
-            LongKmer::<2>::from_ascii(b"ACGT").unwrap(),
-            LongKmer::<2>::from_ascii(b"AGGT").unwrap(),
-            LongKmer::<2>::from_ascii(b"GGAA").unwrap(),
-            LongKmer::<2>::from_ascii(b"GGGT").unwrap()
-        ];
-        let dummies = [
-            (LongKmer::<2>::from_ascii(b"AAAA").unwrap(),0), // This is actually the empty dummy so it's not in the A-block
-            (LongKmer::<2>::from_ascii(b"AAAA").unwrap(),1),
-            (LongKmer::<2>::from_ascii(b"ACAA").unwrap(),2),
-            (LongKmer::<2>::from_ascii(b"ACAA").unwrap(),3),
-            (LongKmer::<2>::from_ascii(b"GGTT").unwrap(),3),
-        ];
-
-        let mut temp_file_manager = crate::tempfile::TempFileManager::new(std::path::Path::new("temp"));
-
-        let mut nondummy_file = temp_file_manager.create_new_file("test-", 10, ".nondummy");
-        let mut dummy_file = temp_file_manager.create_new_file("test-", 10, ".dummy");
-        let nondummy_path = nondummy_file.path.clone();
-        let dummy_path = dummy_file.path.clone();
-
-        for kmer in nondummies.iter(){
-            kmer.serialize(&mut nondummy_file).unwrap();
-        }
-        for (kmer, len) in dummies.iter(){
-            kmer.serialize(&mut dummy_file).unwrap();
-            let len_byte = *len as u8;
-            dummy_file.write_all(&[len_byte]).unwrap();
-        }
-
-        // Flush
-        dummy_file.flush().unwrap();
-        nondummy_file.flush().unwrap();
-
-        let char_cursors = init_char_cursors(&dummy_path, &nondummy_path, 4, 4);
-
-        assert_eq!(char_cursors[0].peek(), Some((LongKmer::<2>::from_ascii(b"AAAA").unwrap(), 1))); // A
-        assert_eq!(char_cursors[1].peek(), Some((LongKmer::<2>::from_ascii(b"GGAA").unwrap(), 4))); // C
-        assert_eq!(char_cursors[2].peek(), Some((LongKmer::<2>::from_ascii(b"GGAA").unwrap(), 4))); // G
-        assert_eq!(char_cursors[3].peek(), None); // T
-
-    }
-}
\ No newline at end of file
+// #[cfg(test)]
+// mod tests{
+
+//     use std::io::Write;
+
+//     use super::*;
+
+//     #[test]
+//     fn test_init_char_cursors(){
+//         let nondummies = [
+//             LongKmer::<2>::from_ascii(b"ACGT").unwrap(),
+//             LongKmer::<2>::from_ascii(b"AGGT").unwrap(),
+//             LongKmer::<2>::from_ascii(b"GGAA").unwrap(),
+//             LongKmer::<2>::from_ascii(b"GGGT").unwrap()
+//         ];
+//         let dummies = [
+//             (LongKmer::<2>::from_ascii(b"AAAA").unwrap(),0), // This is actually the empty dummy so it's not in the A-block
+//             (LongKmer::<2>::from_ascii(b"AAAA").unwrap(),1),
+//             (LongKmer::<2>::from_ascii(b"ACAA").unwrap(),2),
+//             (LongKmer::<2>::from_ascii(b"ACAA").unwrap(),3),
+//             (LongKmer::<2>::from_ascii(b"GGTT").unwrap(),3),
+//         ];
+
+//         let mut temp_file_manager = crate::tempfile::TempFileManager::new();
+
+//         let mut nondummy_file = temp_file_manager.create_new_file("test-", 10, ".nondummy");
+//         let mut dummy_file = temp_file_manager.create_new_file("test-", 10, ".dummy");
+
+//         for kmer in nondummies.iter(){
+//             kmer.serialize(&mut nondummy_file).unwrap();
+//         }
+//         for (kmer, len) in dummies.iter(){
+//             kmer.serialize(&mut dummy_file).unwrap();
+//             let len_byte = *len as u8;
+//             dummy_file.write_all(&[len_byte]).unwrap();
+//         }
+
+//         // Flush
+//         dummy_file.flush().unwrap();
+//         nondummy_file.flush().unwrap();
+
+//         let char_cursors = init_char_cursors(&mut dummy_file, &mut nondummy_file, 4, 4);
+
+//         assert_eq!(char_cursors[0].peek(), Some((LongKmer::<2>::from_ascii(b"AAAA").unwrap(), 1))); // A
+//         assert_eq!(char_cursors[1].peek(), Some((LongKmer::<2>::from_ascii(b"GGAA").unwrap(), 4))); // C
+//         assert_eq!(char_cursors[2].peek(), Some((LongKmer::<2>::from_ascii(b"GGAA").unwrap(), 4))); // G
+//         assert_eq!(char_cursors[3].peek(), None); // T
+
+//     }
+// }
diff --git a/src/bitpacked_kmer_sorting/dummies.rs b/src/bitpacked_kmer_sorting/dummies.rs
index 8a1c909..9b9bf93 100644
--- a/src/bitpacked_kmer_sorting/dummies.rs
+++ b/src/bitpacked_kmer_sorting/dummies.rs
@@ -1,10 +1,16 @@
+use std::borrow::BorrowMut;
 use std::io::{BufWriter, Write};
 
 use super::kmer::LongKmer;
 use crate::tempfile::TempFileManager;
+use crate::tempfile::TempFile;
 use simple_sds_sbwt::raw_vector::*;
 use rayon::prelude::*;
 
+use crate::bitpacked_kmer_sorting::cursors::reset_reader_position;
+use crate::bitpacked_kmer_sorting::cursors::rewind_reader;
+
+#[allow(dead_code)]
 struct NullReader{}
 
 impl std::io::Read for NullReader{
@@ -14,53 +20,58 @@ impl std::io::Read for NullReader{
 }
 
 // We take in a path and not a file object because we need multiple readers to the same file
-pub fn get_sorted_dummies<const B: usize>(sorted_kmers_filepath: &std::path::Path, sigma: usize, k: usize, temp_file_manager: &mut TempFileManager) -> Vec<(LongKmer::<B>, u8)>{
+pub fn get_sorted_dummies<const B: usize>(sorted_kmers: &mut TempFile, sigma: usize, k: usize, temp_file_manager: &mut TempFileManager) -> Vec<(LongKmer::<B>, u8)>{
 
     // Todo: I'm using dummy merger cursors with an empty dummy file. Should refactor things to manage without the
     // empty dummy file.
 
     // Number of k-mers in file
-    let n = std::fs::metadata(sorted_kmers_filepath).unwrap().len() as usize / LongKmer::<B>::byte_size();
+    let n = sorted_kmers.avail_in() as usize / LongKmer::<B>::byte_size();
 
     let mut has_predecessor = simple_sds_sbwt::raw_vector::RawVector::new();
     has_predecessor.resize(n, false);
 
-    let emptyfile = temp_file_manager.create_new_file("empty-", 10, ".bin");
-    let mut char_cursors = crate::bitpacked_kmer_sorting::cursors::init_char_cursors::<B>(&emptyfile.path, sorted_kmers_filepath, k, sigma);
+    let mut emptyfile = temp_file_manager.create_new_file("empty-", 10, ".bin");
+    let char_cursors = crate::bitpacked_kmer_sorting::cursors::init_char_cursor_positions::<B>(&mut emptyfile, sorted_kmers, k, sigma);
 
-    let global_cursor = crate::bitpacked_kmer_sorting::cursors::DummyNodeMerger::new(
-        std::io::BufReader::new(std::fs::File::open(&emptyfile.path).unwrap()),
-        std::io::BufReader::new(std::fs::File::open(sorted_kmers_filepath).unwrap()),
+    let mut global_cursor = crate::bitpacked_kmer_sorting::cursors::DummyNodeMerger::new(
+        &mut emptyfile,
+        sorted_kmers,
         k,
     );
 
-    for (x, _) in global_cursor{
-        // x is reversed
-        for c in 0..(sigma as u8){
-            // Shiting a reversed k-mer to the right means shifting the original k-mer to the left
+    let xs: Vec<(LongKmer::<B>, u8)> = global_cursor.borrow_mut().map(|x| {
+        x
+    }).collect();
+
+    for c in 0..(sigma as u8) {
+        reset_reader_position(&mut global_cursor,
+                              char_cursors[c as usize].0.0,
+                              char_cursors[c as usize].1.0,
+                              char_cursors[c as usize].0.1 as usize,
+                              char_cursors[c as usize].1.1 as usize);
+
+        xs.iter().for_each(|(x, _)| {
             let xc = x.set_from_left(k-1, 0).right_shift(1).set_from_left(0, c);
-            while char_cursors[c as usize].peek().is_some(){
-                match char_cursors[c as usize].peek().unwrap().0.cmp(&xc) {
+
+            while global_cursor.peek().is_some(){
+                match global_cursor.peek().unwrap().0.cmp(&xc) {
                     std::cmp::Ordering::Greater => break,
                     std::cmp::Ordering::Equal => {
-                        has_predecessor.set_bit(char_cursors[c as usize].nondummy_position(), true);
-                        char_cursors[c as usize].next(); // Advance
+                        has_predecessor.set_bit(global_cursor.nondummy_position(), true);
+                        global_cursor.next(); // Advance
                         break
                     },
                     std::cmp::Ordering::Less => {
-                        char_cursors[c as usize].next(); // Advance
+                        global_cursor.next(); // Advance
                         // no break
                     }
                 }
             }
-        }
+        });
     }
 
-    let mut global_cursor = crate::bitpacked_kmer_sorting::cursors::DummyNodeMerger::new(
-        std::io::BufReader::new(std::fs::File::open(&emptyfile.path).unwrap()),
-        std::io::BufReader::new(std::fs::File::open(sorted_kmers_filepath).unwrap()),
-        k,
-    ); // New global cursor
+    rewind_reader(&mut global_cursor);
 
     // Todo: stream to memory and sort there
     let mut required_dummies = Vec::<(LongKmer::<B>, u8)>::new(); // Pairs (data, length)
@@ -89,11 +100,11 @@ pub fn get_sorted_dummies<const B: usize>(sorted_kmers_filepath: &std::path::Pat
 
 }
 
-pub fn write_to_disk<const B: usize>(dummies: Vec<(LongKmer::<B>, u8)>, writer: &mut std::fs::File){   
+pub fn write_to_disk<const B: usize>(dummies: Vec<(LongKmer::<B>, u8)>, writer: &mut TempFile){
     let mut bw = BufWriter::new(writer);
     for (kmer, len) in dummies.iter(){
         kmer.serialize(&mut bw).unwrap();
         bw.write_all(&[*len]).unwrap();
     }
     bw.flush().unwrap();
-}
\ No newline at end of file
+}
diff --git a/src/bitpacked_kmer_sorting/kmer.rs b/src/bitpacked_kmer_sorting/kmer.rs
index 80a7fed..dda969f 100644
--- a/src/bitpacked_kmer_sorting/kmer.rs
+++ b/src/bitpacked_kmer_sorting/kmer.rs
@@ -6,6 +6,7 @@ pub struct Kmer{
 }
 
 #[derive(Debug)]
+#[allow(dead_code)]
 pub enum KmerEncodingError{
     InvalidNucleotide(char), // contains the offending char
     TooLong(usize), // Contains the length of the k-mer which was too long
diff --git a/src/bitpacked_kmer_sorting/kmer_splitter.rs b/src/bitpacked_kmer_sorting/kmer_splitter.rs
index 79eb686..df17ddd 100644
--- a/src/bitpacked_kmer_sorting/kmer_splitter.rs
+++ b/src/bitpacked_kmer_sorting/kmer_splitter.rs
@@ -3,7 +3,11 @@ use super::kmer_chunk::KmerChunk;
 use crate::tempfile::{TempFile, TempFileManager};
 use crate::util::DNA_ALPHABET;
 use std::io::{BufWriter, Seek, Write};
-use std::thread;
+use std::borrow::BorrowMut;
+
+use rayon::iter::IntoParallelRefIterator;
+use rayon::iter::IntoParallelRefMutIterator;
+use rayon::iter::ParallelIterator;
 
 fn colex_sorted_binmers(bin_prefix_len: usize) -> Vec<Vec<u8>> {
     let mut binmers = Vec::<Vec<u8>>::new();
@@ -19,7 +23,7 @@ fn colex_sorted_binmers(bin_prefix_len: usize) -> Vec<Vec<u8>> {
     binmers
 }
 
-pub fn split_to_bins<const B: usize, IN: crate::SeqStream + Send>(mut seqs: IN, k: usize, mem_gb: usize, n_threads: usize, dedup_batches: bool, temp_file_manager: &mut TempFileManager) -> Vec<TempFile>{
+pub fn split_to_bins<const B: usize, IN: crate::SeqStream + Send>(mut seqs: IN, k: usize, _mem_gb: usize, _n_threads: usize, _dedup_batches: bool, temp_file_manager: &mut TempFileManager) -> Vec<TempFile>{
 
     // Suppose we have a memory budget of m bytes and t threads.
     // Suppose each k-mer takes s bytes and there are 64 bins.
@@ -31,220 +35,70 @@ pub fn split_to_bins<const B: usize, IN: crate::SeqStream + Send>(mut seqs: IN,
     // b = m / (64bt)
 
     // Wrap to scope to be able to borrow seqs for the producer thread even when it's not 'static.
-    std::thread::scope(|scope| {
-
-        let bin_prefix_len = 3_usize; // If you update this you must update all the logic below
-        let n_bins = (4_usize).pow(bin_prefix_len as u32); // 64
-        let producer_buf_size = 1_000_000_usize; // TODO: respect this
-        let encoder_bin_buf_size = mem_gb * (1_usize << 30) / ((n_bins * LongKmer::<B>::byte_size()) * n_threads);
-
-        log::info!("Splitting k-mers into {} bins", n_bins);
-        log::info!("Bin buffer size: {}", encoder_bin_buf_size);
-
-        use crossbeam::crossbeam_channel::bounded;
-        let (parser_out, encoder_in) = bounded(4);
-        let (encoder_out, writer_in) = bounded(4);
-
-        // Create producer
-        let producer_handle = scope.spawn(move || {
-            let mut buf = Vec::<Box<[u8]>>::new();
-            let mut current_total_buffer_size = 0_usize;
-            
-            while let Some(seq) = seqs.stream_next(){
-                current_total_buffer_size += seq.len();
-                let mut seq_copy = seq.to_owned();
-                seq_copy.reverse(); // Reverse to get colex sorting
-                buf.push(seq_copy.into_boxed_slice());
-                if current_total_buffer_size > producer_buf_size{
-                    let mut sendbuf = Vec::<Box<[u8]>>::new();
-                    std::mem::swap(&mut sendbuf, &mut buf);
-                    parser_out.send(sendbuf).unwrap();
-                    current_total_buffer_size = 0;
-                }
-            }
-            
-            parser_out.send(buf).unwrap();
-            drop(parser_out);
-        });
-
-        // Create encoder-splitters
-        let mut encoder_handles = Vec::<thread::JoinHandle::<()>>::new();
-        for _ in 0..n_threads{
-            let receiver_clone = encoder_in.clone();
-            let sender_clone = encoder_out.clone();
-            encoder_handles.push(std::thread::spawn(move || {
-                let mut bin_buffers = vec![Vec::<LongKmer::<B>>::new(); n_bins];
-                for buf in bin_buffers.iter_mut(){
-                    buf.reserve_exact(encoder_bin_buf_size);
-                }
-                while let Ok(batch) = receiver_clone.recv(){
-                    for seq in batch{
-                        for kmer in seq.windows(k){
-                            match LongKmer::<B>::from_ascii(kmer) {
-                                Ok(kmer) => {
-                                    let bin_id = kmer.get_from_left(0) as usize * 16 + kmer.get_from_left(1) as usize * 4 + kmer.get_from_left(2) as usize; // Interpret nucleotides in base-4
-                                    bin_buffers[bin_id].push(kmer);
-                                    if bin_buffers[bin_id].len() == encoder_bin_buf_size{
-                                        if dedup_batches{
-                                            bin_buffers[bin_id].sort_unstable();
-                                            bin_buffers[bin_id].dedup();
-                                        }
-                                        sender_clone.send(bin_buffers[bin_id].clone()).unwrap();
-                                        bin_buffers[bin_id].clear();
-                                    }
-                                }
-                                Err(KmerEncodingError::InvalidNucleotide(_)) => (), // Ignore
-                                Err(KmerEncodingError::TooLong(_)) => panic!("k = {} is too long", k),
-                            }        
-                        }
-                    }
-                }
-
-                // Send remaining buffers
-                for mut b in bin_buffers{
-                    if dedup_batches{
-                        b.sort_unstable();
-                        b.dedup();
-                    }
-                    sender_clone.send(b).unwrap();
-                }
-            }));
-        }
+    let bin_prefix_len = 3_usize; // If you update this you must update all the logic below
+    let n_bins = (4_usize).pow(bin_prefix_len as u32); // 64
 
-        // Create writers
-        let mut bin_writers = 
-            Vec::<std::io::BufWriter::<TempFile>>::new();
+    log::info!("Splitting k-mers into {} bins", n_bins);
 
-        for binmer in colex_sorted_binmers(bin_prefix_len) {
-            let name_prefix = format!("sbwt-temp-{}-", String::from_utf8(binmer).unwrap());
-            let f = temp_file_manager.create_new_file(&name_prefix, 8, ".bin");
-            bin_writers.push(BufWriter::new(f));
-        }
-
-
-        let writer_handle = thread::spawn( move || {
-            while let Ok(batch) = writer_in.recv(){
-                if !batch.is_empty() {
-                    let bin_id = batch[0].get_from_left(0) as usize * 16 + batch[0].get_from_left(1) as usize * 4 + batch[0].get_from_left(2) as usize; // Intepret nucleotides in base-4
-                    let bin_file = &mut bin_writers[bin_id];
-                    for kmer in batch{
-                        kmer.serialize(bin_file).unwrap(); // Todo: write all at once
-                    }
-                }
-            }
-            bin_writers
-        });
+    let mut buf = Vec::<Box<[u8]>>::new();
+    while let Some(seq) = seqs.stream_next() {
+        let mut seq_copy = seq.to_owned();
+        seq_copy.reverse(); // Reverse to get colex sorting
+        buf.push(seq_copy.into_boxed_slice());
+    }
 
-        producer_handle.join().unwrap();
-        drop(encoder_in); // Close the channel
-        for h in encoder_handles{
-            h.join().unwrap();
-        }
-        drop(encoder_out); // Close the channel
+    // Create writers
+    let mut bin_writers = colex_sorted_binmers(bin_prefix_len).into_iter().map(|binmer| {
+        let name_prefix = format!("sbwt-temp-{}-", String::from_utf8(binmer).unwrap());
+        temp_file_manager.create_new_file(&name_prefix, 8, ".bin")
+    }).collect::<Vec<TempFile>>();
+
+    let kmers: Vec<LongKmer::<B>> = buf.par_iter().map(|seq| {
+        seq.windows(k).filter_map(|kmer| {
+            LongKmer::<B>::from_ascii(kmer).ok()
+        }).collect::<Vec<LongKmer::<B>>>()
+    }).flatten().collect();
+
+    kmers.iter().for_each(|kmer| {
+        let bin_id = kmer.get_from_left(0) as usize * 16 + kmer.get_from_left(1) as usize * 4 + kmer.get_from_left(2) as usize; // Interpret nucleotides in base-4
+        let bin_file = &mut bin_writers[bin_id];
+        kmer.serialize(bin_file).unwrap(); // Todo: write all at once
+    });
 
-        // Return the TempFiles
-        let writers = writer_handle.join().unwrap();
-        let mut writers: Vec<TempFile> = writers.into_iter().map(|w| w.into_inner().unwrap()).collect();
-        for w in writers.iter_mut(){
-            w.file.seek(std::io::SeekFrom::Start(0)).unwrap();
+    // Return the TempFiles
+    for w in bin_writers.iter_mut(){
+        match w.file.rewind() {
+            Ok(_) => (),
+            Err(e) => panic!("Couldn't rewind file: {}", e)
         }
-        writers
+    }
+    bin_writers
 
-    })
 }
 
 // Overwrite the files with sorted and deduplicates files. Returns back the files after overwriting.
-pub fn par_sort_and_dedup_bin_files<const B: usize>(bin_files: Vec<TempFile>, mem_gb: usize, n_threads: usize) -> Vec<TempFile> {
-
-    let filesizes = bin_files.iter().map(|f| f.path.metadata().unwrap().len() as usize).collect::<Vec<usize>>();
-    let mut files_and_sizes = bin_files.into_iter().enumerate().map(|(i, f)| (f, filesizes[i], i)).collect::<Vec<(TempFile, usize, usize)>>();
-        
-    files_and_sizes.sort_by_key(|(_, size, _)| *size);
+pub fn par_sort_and_dedup_bin_files<const B: usize>(bin_files: &mut Vec<TempFile>, _mem_gb: usize, _n_threads: usize) {
 
-    let max_mem = mem_gb * (1_usize << 30);
+    let mut files_and_sizes = bin_files.par_iter_mut().map(|f| {
+        f
+    }).collect::<Vec<&mut TempFile>>();
+    files_and_sizes.sort_by_key(|f| f.avail_in());
 
     log::info!("Sorting k-mer bins");
 
-    use crossbeam::unbounded;
+    files_and_sizes.par_iter_mut().for_each(|f| {
+        // Using debug log level as a more verbose info level
+        let mut reader = std::io::BufReader::new(f.file.borrow_mut());
+        let chunk = KmerChunk::<B>::load(&mut reader).unwrap();
 
-    // A work queue
-    let (queue_sender, queue_recvr) = unbounded::<(TempFile, usize, usize)>(); // File, size, index
+        let mut chunk = chunk.sort();
+        chunk.dedup();
 
-    // A queue to notify the producer that a bin has been processed.
-    // The usize in the channel is the size of the bin that was processed.
-    let (producer_notify, producer_recv_notify) = unbounded::<usize>();
-
-    // Wrap in mutex to share between threads
-    let mut total_size_in_processing = 0_usize;
-
-    // Start the producer
-    let producer_handle = thread::spawn(move || {
-        while !files_and_sizes.is_empty() {
-            // Push as much work to the queue as possible
-            while !files_and_sizes.is_empty(){    
-                let s = files_and_sizes.last().unwrap().1; // Size
-                if total_size_in_processing == 0 || total_size_in_processing + s <= max_mem {
-                    let (f,s,i) = files_and_sizes.pop().unwrap();
-                    queue_sender.send((f, s, i)).unwrap();
-                    total_size_in_processing += s;
-                } else {
-                    break;
-                }
-            }
-
-            let s_done = producer_recv_notify.recv().unwrap(); // Wait for a notification
-            total_size_in_processing -= s_done;
-        }
-
-        // All files have been pushed to the channel
-        drop(queue_sender); // Close the channel
+        // Overwrite the file and seek to start
+        f.file = std::io::Cursor::new(Vec::new());
+        chunk.serialize(f.file.borrow_mut()).unwrap();
+        f.file.seek(std::io::SeekFrom::Start(0)).unwrap();
     });
-
-    let mut consumer_handles = Vec::<thread::JoinHandle<Vec::<(TempFile, usize)>>>::new();
-
-    // Spawn consumers
-    for _ in 0..n_threads{
-        let recv_clone = queue_recvr.clone();
-        let producer_notify = producer_notify.clone();
-
-        consumer_handles.push(std::thread::spawn( move || {
-            let mut processed_files = Vec::<(TempFile, usize)>::new(); // File, index
-            while let Ok((mut f, s, i)) = recv_clone.recv(){
-                // Using debug log level as a more verbose info level
-                log::debug!("Sorting bin {} of size {}", f.path.display(), s);
-                let mut reader = std::io::BufReader::new(&f.file);
-                let chunk = KmerChunk::<B>::load(&mut reader).unwrap();
-        
-                let mut chunk = chunk.sort();
-                chunk.dedup();
-
-                // Overwrite the file and seek to start
-                f.file.set_len(0).unwrap();
-                f.file.seek(std::io::SeekFrom::Start(0)).unwrap();
-                let chunk_out = std::io::BufWriter::new(&mut f);
-                chunk.serialize(chunk_out).unwrap();
-                f.flush().unwrap();
-                f.file.seek(std::io::SeekFrom::Start(0)).unwrap();
-
-                // Notify the producer that s bytes have been processed and
-                // new work can possibly be pushed to the queue.
-                let _ = producer_notify.send(s); // This may fail if the producer has already exited. That is ok.
-
-                processed_files.push((f,i));
-            }
-            processed_files // Return to owner
-        }));
-    }
-
-    let mut processed_files = Vec::<(TempFile, usize)>::new();
-    producer_handle.join().unwrap();
-    for h in consumer_handles{
-        processed_files.extend(h.join().unwrap());
-    }
-    processed_files.sort_by(|(_, i1), (_, i2)| i1.cmp(i2));
-
-    processed_files.into_iter().map(|(f,_)| f).collect() // Return to owner
-
 }
 
 // The original files are deleted
@@ -253,7 +107,7 @@ pub fn concat_files(infiles: Vec<TempFile>, out_writer: &mut impl std::io::Write
     for mut fp in infiles {
         let mut reader = std::io::BufReader::new(&mut fp.file);
         std::io::copy(&mut reader, &mut bw).unwrap();
-        // fp is dropped here, which deletes the file
+        drop(fp);
     }
     bw.flush().unwrap();
 }
diff --git a/src/bitpacked_kmer_sorting/kmer_splitter.rs~ b/src/bitpacked_kmer_sorting/kmer_splitter.rs~
new file mode 100644
index 0000000..68b0da3
--- /dev/null
+++ b/src/bitpacked_kmer_sorting/kmer_splitter.rs~
@@ -0,0 +1,148 @@
+use super::kmer::*;
+use super::kmer_chunk::KmerChunk;
+use crate::tempfile::{TempFile, TempFileManager};
+use crate::util::DNA_ALPHABET;
+use std::io::{BufWriter, Seek, Write};
+use std::borrow::BorrowMut;
+
+fn colex_sorted_binmers(bin_prefix_len: usize) -> Vec<Vec<u8>> {
+    let mut binmers = Vec::<Vec<u8>>::new();
+    for i in 0..(4_usize.pow(bin_prefix_len as u32)){
+        let mut binmer = Vec::<u8>::new();
+        let mut j = i;
+        for _ in 0..bin_prefix_len{
+            binmer.push(DNA_ALPHABET[j % 4]);
+            j /= 4;
+        }
+        binmers.push(binmer);
+    }
+    binmers
+}
+
+pub fn split_to_bins<const B: usize, IN: crate::SeqStream + Send>(mut seqs: IN, k: usize, mem_gb: usize, n_threads: usize, dedup_batches: bool, temp_file_manager: &mut TempFileManager) -> Vec<TempFile>{
+
+    // Suppose we have a memory budget of m bytes and t threads.
+    // Suppose each k-mer takes s bytes and there are 64 bins.
+    // Let b be the number of k-mers in each splitter thread bin buffer.
+    // A splitter thread uses 64bs bytes
+    // In total the splitter threads use 64bst threads.
+    // So, we need:
+    // 64bbt = m
+    // b = m / (64bt)
+
+    // Wrap to scope to be able to borrow seqs for the producer thread even when it's not 'static.
+    let bin_prefix_len = 3_usize; // If you update this you must update all the logic below
+    let n_bins = (4_usize).pow(bin_prefix_len as u32); // 64
+    let mem_gb = (mem_gb as usize * (1_usize << 30) as usize);
+    let encoder_bin_buf_size = mem_gb / ((n_bins as usize * LongKmer::<B>::byte_size() as usize) * n_threads as usize);
+
+    log::info!("Splitting k-mers into {} bins", n_bins);
+    let mut bin_buffers = vec![Vec::<LongKmer::<B>>::new(); n_bins];
+    for buf in bin_buffers.iter_mut(){
+        buf.reserve_exact(encoder_bin_buf_size.try_into().unwrap());
+    }
+
+    let mut buf = Vec::<Box<[u8]>>::new();
+    while let Some(seq) = seqs.stream_next() {
+	let mut seq_copy = seq.to_owned();
+        seq_copy.reverse(); // Reverse to get colex sorting
+	buf.push(seq_copy.into_boxed_slice());
+    }
+
+    for seq in &buf {
+	for kmer in seq.windows(k){
+            match LongKmer::<B>::from_ascii(kmer) {
+		Ok(kmer) => {
+                    let bin_id = kmer.get_from_left(0) as usize * 16 + kmer.get_from_left(1) as usize * 4 + kmer.get_from_left(2) as usize; // Interpret nucleotides in base-4
+                    bin_buffers[bin_id].push(kmer);
+		}
+		Err(KmerEncodingError::InvalidNucleotide(_)) => (), // Ignore
+		Err(KmerEncodingError::TooLong(_)) => panic!("k = {} is too long", k),
+            }
+	}
+    }
+
+    // Send remaining buffers
+    if dedup_batches {
+        for b in &mut bin_buffers{
+            b.sort_unstable();
+            b.dedup();
+        }
+    }
+
+    // Create writers
+    let mut bin_writers = Vec::<std::io::BufWriter::<TempFile>>::new();
+
+    for binmer in colex_sorted_binmers(bin_prefix_len) {
+        let name_prefix = format!("sbwt-temp-{}-", String::from_utf8(binmer).unwrap());
+        let f = temp_file_manager.create_new_file(&name_prefix, 8, ".bin");
+        bin_writers.push(BufWriter::new(f));
+    }
+
+
+    bin_buffers.iter().for_each(|batch| {
+        if !batch.is_empty() {
+            let bin_id = batch[0].get_from_left(0) as usize * 16 + batch[0].get_from_left(1) as usize * 4 + batch[0].get_from_left(2) as usize; // Intepret nucleotides in base-4
+            let bin_file = &mut bin_writers[bin_id];
+            for kmer in batch{
+                kmer.serialize(bin_file).unwrap(); // Todo: write all at once
+            }
+        }
+    });
+
+    // Return the TempFiles
+    let mut writers: Vec<TempFile> = bin_writers.into_iter().map(|w| w.into_inner().unwrap()).collect();
+    for w in writers.iter_mut(){
+        w.file.seek(std::io::SeekFrom::Start(0)).unwrap();
+    }
+    writers
+
+}
+
+// Overwrite the files with sorted and deduplicates files. Returns back the files after overwriting.
+pub fn par_sort_and_dedup_bin_files<const B: usize>(bin_files: &mut Vec<TempFile>, mem_gb: usize, n_threads: usize) {
+
+    let filesizes = bin_files.iter().map(|f| f.avail_in() as usize).collect::<Vec<usize>>();
+    let mut files_and_sizes = bin_files.into_iter().enumerate().map(|(i, f)| (f, filesizes[i], i)).collect::<Vec<(&mut TempFile, usize, usize)>>();
+        
+    files_and_sizes.sort_by_key(|(_, size, _)| *size);
+
+    let max_mem = mem_gb * (1_usize << 30);
+
+    log::info!("Sorting k-mer bins");
+
+    files_and_sizes.iter_mut().for_each(|(f, _s, _i)| {
+        // Using debug log level as a more verbose info level
+        let mut reader = std::io::BufReader::new(f.file.borrow_mut());
+        let chunk = KmerChunk::<B>::load(&mut reader).unwrap();
+        
+        let mut chunk = chunk.sort();
+        chunk.dedup();
+
+        // Overwrite the file and seek to start
+	f.file = std::io::Cursor::new(Vec::new());
+        let chunk_out = std::io::BufWriter::new(f.file.borrow_mut());
+        chunk.serialize(chunk_out).unwrap();
+        f.file.seek(std::io::SeekFrom::Start(0)).unwrap();
+    });
+}
+
+// The original files are deleted
+pub fn concat_files(infiles: Vec<TempFile>, out_writer: &mut impl std::io::Write){
+    let mut bw = BufWriter::new(out_writer);
+    for mut fp in infiles {
+        let mut reader = std::io::BufReader::new(&mut fp.file);
+        std::io::copy(&mut reader, &mut bw).unwrap();
+        // fp is dropped here, which deletes the file
+    }
+    bw.flush().unwrap();
+}
+
+mod tests {
+    #[test]
+    fn test_colex_sorted_binmers(){
+        let binmers = super::colex_sorted_binmers(2);
+        let ans = vec![b"AA", b"CA", b"GA", b"TA", b"AC", b"CC", b"GC", b"TC", b"AG", b"CG", b"GG", b"TG", b"AT", b"CT", b"GT", b"TT"];
+        assert_eq!(binmers, ans);
+    }
+}
diff --git a/src/bitpacked_kmer_sorting/mod.rs b/src/bitpacked_kmer_sorting/mod.rs
index f4ec05d..11dea66 100644
--- a/src/bitpacked_kmer_sorting/mod.rs
+++ b/src/bitpacked_kmer_sorting/mod.rs
@@ -14,66 +14,62 @@ use crate::{sbwt::{PrefixLookupTable, SbwtIndex}, streaming_index::LcsArray, sub
 /// user-friendly interface. B is the number u64 words in a k-mer.
 pub fn build_with_bitpacked_kmer_sorting<const B: usize, IN: crate::SeqStream + Send, SS: SubsetSeq + Send>(seqs: IN, k: usize, mem_gb: usize, n_threads: usize, dedup_batches: bool, build_lcs: bool, temp_file_manager: &mut TempFileManager) -> (SbwtIndex::<SS>, Option<LcsArray>) {
 
-    let thread_pool = rayon::ThreadPoolBuilder::new().num_threads(n_threads).build().unwrap();
+    let sigma = DNA_ALPHABET.len();
 
-    thread_pool.install(||{
-        let sigma = DNA_ALPHABET.len(); 
+    log::info!("Splitting k-mers into bins");
+    let mut bin_files = kmer_splitter::split_to_bins::<B, IN>(seqs, k, mem_gb, n_threads, dedup_batches, temp_file_manager);
 
-        log::info!("Splitting k-mers into bins");
-        let bin_files = kmer_splitter::split_to_bins::<B, IN>(seqs, k, mem_gb, n_threads, dedup_batches, temp_file_manager);
+    log::info!("Sorting and deduplicating bins");
+    kmer_splitter::par_sort_and_dedup_bin_files::<B>(&mut bin_files, mem_gb, n_threads);
 
-        log::info!("Sorting and deduplicating bins");
-        let bin_files = kmer_splitter::par_sort_and_dedup_bin_files::<B>(bin_files, mem_gb, n_threads);
+    let mut kmers_file = temp_file_manager.create_new_file("kmers-", 10, ".bin");
+    kmer_splitter::concat_files(bin_files, &mut kmers_file.file);
+    kmers_file.file.seek(std::io::SeekFrom::Start(0)).unwrap();
 
-        let mut kmers_file = temp_file_manager.create_new_file("kmers-", 10, ".bin");
-        kmer_splitter::concat_files(bin_files, &mut kmers_file.file);
-        kmers_file.file.seek(std::io::SeekFrom::Start(0)).unwrap();
+    let n_kmers = kmers_file.avail_in() / kmer::LongKmer::<B>::byte_size();
 
-        let n_kmers = std::fs::metadata(&kmers_file.path).unwrap().len() as usize / kmer::LongKmer::<B>::byte_size();
+    log::info!("{} distinct k-mers found", n_kmers);
+    let required_dummies = dummies::get_sorted_dummies::<B>(&mut kmers_file, sigma, k, temp_file_manager);
 
-        log::info!("{} distinct k-mers found", n_kmers);
+    let n = n_kmers + required_dummies.len();
 
-        let required_dummies = dummies::get_sorted_dummies::<B>(&kmers_file.path, sigma, k, temp_file_manager);
-
-        log::info!("{} dummy nodes needed", required_dummies.len());
-
-        let n = n_kmers + required_dummies.len();
-
-        // Write dummies to disk
-        let mut dummy_file = temp_file_manager.create_new_file("dummies-", 10, ".bin");
-        dummies::write_to_disk(required_dummies, &mut dummy_file.file);
-        
-        log::info!("Constructing the sbwt subset sequence");
-
-        let char_cursors = cursors::init_char_cursors::<B>(&dummy_file.path, &kmers_file.path, k, sigma);
-
-        let global_cursor = cursors::DummyNodeMerger::new(
-            std::io::BufReader::new(std::fs::File::open(&dummy_file.path).unwrap()),
-            std::io::BufReader::new(std::fs::File::open(&kmers_file.path).unwrap()),
-            k,
-        );
-
-        let (rawrows, lcs) = cursors::build_sbwt_bit_vectors(global_cursor, char_cursors, n, k, sigma, build_lcs);
-
-        // Create the C array
-        #[allow(non_snake_case)] // C-array is an established convention in BWT indexes
-        let C: Vec<usize> = crate::util::get_C_array(&rawrows);
-
-        log::info!("Building the subset rank structure");
-        let mut subsetseq = SS::new_from_bit_vectors(rawrows.into_iter().map(simple_sds_sbwt::bit_vector::BitVector::from).collect());
-        subsetseq.build_rank();
-        let n_sets = subsetseq.len();
-        let (mut index, lcs) = (SbwtIndex::<SS>::from_components(
-            subsetseq,
-            n_kmers,
-            k,
-            C,
-            PrefixLookupTable::new_empty(n_sets))
-        , lcs.map(LcsArray::new));
-
-        let lut = PrefixLookupTable::new(&index, 8);
-        index.set_lookup_table(lut);
-        (index, lcs)
-    })
+    // Write dummies to disk
+    let mut dummy_file = temp_file_manager.create_new_file("dummies-", 10, ".bin");
+    dummies::write_to_disk(required_dummies, &mut dummy_file);
     
-}
\ No newline at end of file
+    log::info!("Constructing the sbwt subset sequence");
+
+    let char_cursors = cursors::init_char_cursor_positions::<B>(&mut dummy_file, &mut kmers_file, k, sigma);
+
+    dummy_file.file.seek(std::io::SeekFrom::Start(0)).unwrap();
+    kmers_file.file.seek(std::io::SeekFrom::Start(0)).unwrap();
+
+    let global_cursor = cursors::DummyNodeMerger::new(
+        &mut dummy_file,
+        &mut kmers_file,
+        k,
+    );
+
+    let (rawrows, lcs) = cursors::build_sbwt_bit_vectors::<B>(global_cursor, char_cursors, n, k, sigma, build_lcs);
+
+    // Create the C array
+    #[allow(non_snake_case)] // C-array is an established convention in BWT indexes
+    let C: Vec<usize> = crate::util::get_C_array(&rawrows);
+
+    log::info!("Building the subset rank structure");
+    let mut subsetseq = SS::new_from_bit_vectors(rawrows.into_iter().map(simple_sds_sbwt::bit_vector::BitVector::from).collect());
+    subsetseq.build_rank();
+    let n_sets = subsetseq.len();
+    let (mut index, lcs) = (SbwtIndex::<SS>::from_components(
+        subsetseq,
+        n_kmers,
+        k,
+        C,
+        PrefixLookupTable::new_empty(n_sets))
+			    , lcs.map(LcsArray::new));
+
+    let lut = PrefixLookupTable::new(&index, 8);
+    index.set_lookup_table(lut);
+    (index, lcs)
+
+}
diff --git a/src/builder.rs b/src/builder.rs
index 1384d42..dc7c456 100644
--- a/src/builder.rs
+++ b/src/builder.rs
@@ -1,7 +1,5 @@
 //! A builder pattern interface for building an [SbwtIndex].
 
-use std::str::FromStr;
-
 use crate::{subsetseq::SubsetMatrix, SeqStream};
 use crate::sbwt::{PrefixLookupTable, SbwtIndex};
 use crate::streaming_index::LcsArray;
@@ -51,7 +49,6 @@ pub trait SbwtConstructionAlgorithm {
 pub struct BitPackedKmerSorting{
     mem_gb: usize,
     dedup_batches: bool,
-    temp_dir: std::path::PathBuf,
 }
 
 impl BitPackedKmerSorting {
@@ -61,7 +58,7 @@ impl BitPackedKmerSorting {
     /// - do not deduplicate k-mer batches before sorting.
     /// - use the current directory as the temporary directory.
     pub fn new() -> Self {
-        Self{mem_gb: 4, dedup_batches: false, temp_dir: std::path::PathBuf::from_str(".").unwrap()}
+        Self{mem_gb: 4, dedup_batches: false}
     }
 
     /// Set the amount of memory to use in gigabytes. This is not strictly enforced, but the algorithm will try to stay within this limit.
@@ -75,20 +72,13 @@ impl BitPackedKmerSorting {
         self.dedup_batches = enable;
         self
     }
-
-    /// Set the temporary directory where the algorithm can store temporary files.
-    pub fn temp_dir(mut self, temp_dir: &std::path::Path) -> Self {
-        self.temp_dir = temp_dir.to_path_buf();
-        std::fs::create_dir_all(&self.temp_dir).unwrap();
-        self
-    }
 }
 
 impl SbwtConstructionAlgorithm for BitPackedKmerSorting {
     fn run<SS: SeqStream + Send>(self, input: SS, k: usize, n_threads: usize, build_lcs: bool) -> (SbwtIndex<SubsetMatrix>, Option<LcsArray>) {
         let mem_gb = self.mem_gb;
         let dedup_batches = self.dedup_batches;
-        let mut temp_file_manager = crate::tempfile::TempFileManager::new(&self.temp_dir);
+        let mut temp_file_manager = crate::tempfile::TempFileManager::new();
         match k {
             0..=32 => {
                 crate::bitpacked_kmer_sorting::build_with_bitpacked_kmer_sorting::<1,_,SubsetMatrix>(input, k, mem_gb, n_threads, dedup_batches, build_lcs, &mut temp_file_manager)
diff --git a/src/lib.rs b/src/lib.rs
index 2aafdc8..3d0ae7d 100644
--- a/src/lib.rs
+++ b/src/lib.rs
@@ -33,8 +33,7 @@
 //!     .k(6).n_threads(4).build_lcs(true).add_rev_comp(true)
 //!     .algorithm(BitPackedKmerSorting::new()
 //!         .mem_gb(2)
-//!         .dedup_batches(false)
-//!         .temp_dir(Path::new("./temp")))
+//!         .dedup_batches(false))
 //!     .run(seq_stream);
 //!
 //! // Query a k-mer
diff --git a/src/tempfile.rs b/src/tempfile.rs
index 5ebfcc9..3e5ab51 100644
--- a/src/tempfile.rs
+++ b/src/tempfile.rs
@@ -1,133 +1,92 @@
-use std::path::{Path, PathBuf};
-
-use rand::{Rng, SeedableRng};
+use std::io::Cursor;
 
 /// A simple struct to manage temporary files.
 /// All files will be created in the directory specified in the struct.
 pub struct TempFileManager {
-    directory: PathBuf,
-    rng: rand::rngs::StdRng,
 }
 
 /// A struct encapsulating a std::fs::File and its path.
 /// When the TempFile is dropped, the file is deleted.
-#[derive(Debug)]
+#[derive(Debug, Default)]
 pub struct TempFile {
-    pub path: PathBuf,
-    pub file: std::fs::File,
+    pub file: Cursor<Vec<u8>>,
 }
 
 impl Drop for TempFile {
     fn drop(&mut self) {
-        log::trace!("Dropping temp file {}", self.path.display());
-        std::fs::remove_file(&self.path).unwrap();
+	self.file.get_mut().clear();
     }
 }
 
 impl std::io::Write for TempFile {
     fn write(&mut self, buf: &[u8]) -> std::io::Result<usize> {
-        self.file.write(buf)
+	self.file.write(buf)
     }
 
     fn flush(&mut self) -> std::io::Result<()> {
-        self.file.flush()
+	self.file.flush()
     }
 }
 
 impl std::io::Read for TempFile {
     fn read(&mut self, buf: &mut [u8]) -> std::io::Result<usize> {
-        self.file.read(buf)
+	self.file.read(buf)
     }
 }
 
-impl TempFileManager {
-
-    fn get_random_filename(&mut self, prefix: &str, random_infix_length: usize, suffix: &str) -> PathBuf {
-
-            let mut random_part = String::new();
-            for _ in 0..random_infix_length {
-                let r = self.rng.gen_range(0, 26);
-                let c = b'a' + r; // Random character from a..z
-                random_part.push(c as char);
-            }
-
-            let mut fname = String::new();
-            fname.push_str(prefix);
-            fname.push_str(&random_part);
-            fname.push_str(suffix);
-
-            let mut path = self.directory.clone();
-            path.push(fname);
-            path
+impl TempFile {
+    pub fn avail_in(&self) -> usize {
+	return self.file.get_ref().len();
     }
+}
 
-    pub fn new(directory: &Path) -> Self {
-        let seed = rand::thread_rng().gen();
-        let rng = rand::rngs::StdRng::seed_from_u64(seed);
+impl TempFileManager {
 
-        std::fs::create_dir_all(directory).unwrap();
-        Self {directory: directory.to_path_buf(), rng}
+    pub fn new() -> Self {
+        Self{}
     }
 
     // Creates a new temp file with filename with format:
     // self.directory / prefix + random_infix + suffix.
     // &self is taken as mutable because we use an RNG to generate the infix. 
-    pub fn create_new_file(&mut self, prefix: &str, infix_length: usize, suffix: &str) -> TempFile {
-
-        let mut path = self.get_random_filename(prefix, infix_length, suffix);
-        let mut file = std::fs::File::create_new(&path);
-
-        while let Err(e) = file {
-            match e.kind() {
-                std::io::ErrorKind::AlreadyExists => {
-                    // Try again
-                    log::warn!("Temporary filename collision {}, trying again...", path.display());
-                    path = self.get_random_filename(prefix, infix_length, suffix);
-                    file = std::fs::File::create_new(&path);
-
-                },
-                _ => panic!("Error creating temp file: {} {}", path.display(), e),
-            }
-        }
-
-        log::trace!("Creating temp file {}", path.display());
-        TempFile {path, file: file.unwrap()}
+    pub fn create_new_file(&mut self, _prefix: &str, _infix_length: usize, _suffix: &str) -> TempFile {
+        TempFile {file: Cursor::new(Vec::new())}
     }
 }
 
-#[cfg(test)]
-mod tests {
-    use super::*;
+// #[cfg(test)]
+// mod tests {
+//     use super::*;
 
-    #[test_log::test]
-    fn test_tempfile() {
+//     #[test_log::test]
+//     fn test_tempfile() {
         
-        // Create a random prefix for our temp files. This is to avoid collisions
-        // with files created for previous runs of this test.
-        let seed = rand::thread_rng().gen();
-        let mut rng = rand::rngs::StdRng::seed_from_u64(seed);
-        let mut prefix = rng.gen_range(0, 1000000000).to_string();
-        prefix.push('-');
-
-        let mut temp_file_manager = TempFileManager::new(Path::new("/tmp"));
-
-        let mut files = Vec::<TempFile>::new();
-        let mut paths = Vec::<PathBuf>::new();
-
-        for _ in 0..26 { // Create filename collisions with very high probablity
-            let temp_file = temp_file_manager.create_new_file(&prefix, 1, ".txt");
-            paths.push(temp_file.path.clone());
-            files.push(temp_file);
-        }
-
-        for path in paths.iter() {
-            assert!(path.exists());
-        }
-
-        drop(files); // Should delete all our files
-
-        for path in paths.iter() {
-            assert!(!path.exists());
-        }
-    }
-}
\ No newline at end of file
+//         // Create a random prefix for our temp files. This is to avoid collisions
+//         // with files created for previous runs of this test.
+//         let seed = rand::thread_rng().gen();
+//         let mut rng = rand::rngs::StdRng::seed_from_u64(seed);
+//         let mut prefix = rng.gen_range(0, 1000000000).to_string();
+//         prefix.push('-');
+
+//         let mut temp_file_manager = TempFileManager::new(Path::new("/tmp"));
+
+//         let mut files = Vec::<TempFile>::new();
+//         let mut paths = Vec::<PathBuf>::new();
+
+//         for _ in 0..26 { // Create filename collisions with very high probablity
+//             let temp_file = temp_file_manager.create_new_file(&prefix, 1, ".txt");
+//             paths.push(temp_file.path.clone());
+//             files.push(temp_file);
+//         }
+
+//         for path in paths.iter() {
+//             assert!(path.exists());
+//         }
+
+//         drop(files); // Should delete all our files
+
+//         for path in paths.iter() {
+//             assert!(!path.exists());
+//         }
+//     }
+// }
diff --git a/src/util.rs b/src/util.rs
index 3efd5b1..66dfedf 100644
--- a/src/util.rs
+++ b/src/util.rs
@@ -11,6 +11,7 @@ pub(crate) fn write_bytes<W: std::io::Write>(out: &mut W, bytes: &[u8]) -> std::
 
 // Searcher the range [0..n)
 // Return the index of the answer, or n if does not exist
+#[allow(dead_code)]
 pub(crate) fn binary_search_leftmost_that_fulfills_pred<T, Access: Fn(usize) -> T, Pred: Fn(T) -> bool>(access: Access, pred: Pred, n: usize) -> usize {
     let mut ans = n;
     let mut step = n;
@@ -23,10 +24,25 @@ pub(crate) fn binary_search_leftmost_that_fulfills_pred<T, Access: Fn(usize) ->
     ans
 }
 
+// Searcher the range [0..n)
+// Return the index of the answer, or n if does not exist
+#[allow(dead_code)]
+pub(crate) fn binary_search_leftmost_that_fulfills_pred_mut<T, Access: FnMut(usize) -> T, Pred: FnMut(T) -> bool>(mut access: Access, mut pred: Pred, n: usize) -> usize {
+    let mut ans = n;
+    let mut step = n;
+    while step > 0 {
+        while ans as isize - step as isize >= 0 && pred(access(ans-step)) {
+            ans -= step;
+        }
+        step /= 2;
+    }
+    ans
+}
+
 pub const DNA_ALPHABET: [u8; 4] = [b'A', b'C', b'G', b'T'];
 
 // This bit vector of length 256 marks the ascii values of these characters: acgtACGT
-const IS_DNA: BitArray<[usize; 4]> = bitarr![const 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0];
+const IS_DNA: BitArray<[u32; 8]> = bitarr![const u32, Lsb0; 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0];
 
 pub(crate) fn is_dna(c: u8) -> bool {
     IS_DNA[c as usize]
@@ -67,6 +83,7 @@ pub fn reverse_complement_in_place(seq: &mut [u8]){
     jseqio::reverse_complement_in_place(seq);
 }
 
+#[allow(dead_code)]
 pub(crate) struct FastXReader{
     inner: jseqio::reader::DynamicFastXReader
 }
@@ -125,4 +142,4 @@ impl<'a> crate::SeqStream for VecSeqStream<'a> {
             Some(s)
         }
     } 
-}
\ No newline at end of file
+}
